<?xml version="1.0" encoding="utf-8"?>
<rss xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:sy="http://purl.org/rss/1.0/modules/syndication/" xmlns:media="http://search.yahoo.com/mrss/" version="2.0">
  <channel>
    <title/>
    <atom:link href="https://dropbox.tech/feed" rel="self" type="application/rss+xml"/>
    <link/>
    <description/>
    <lastBuildDate>Tue, 03 Aug 2021 06:00:00 -0700</lastBuildDate>
    <language>en</language>
    <sy:updatePeriod>hourly</sy:updatePeriod>
    <sy:updateFrequency>1</sy:updateFrequency>
    <image>
      <url/>
      <title/>
      <link/>
    </image>
    <item>
      <title>How we’re making Dropbox data centers 100% carbon neutral</title>
      <link>https://dropbox.tech/infrastructure/making-dropbox-data-centers-carbon-neutral</link>
      <dc:creator>Latane Garetson</dc:creator>
      <category>sustainability</category>
      <guid>https://dropbox.tech/infrastructure/making-dropbox-data-centers-carbon-neutral</guid>
      <description><![CDATA[]]></description>
      <pubDate>Tue, 03 Aug 2021 06:00:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>As you may already know, Dropbox runs our infrastructure on a hybrid model—a mix between on-premise hardware and the public cloud. Known as <a href="https://dropbox.tech/infrastructure/inside-the-magic-pocket" target="_blank">Magic Pocket</a>, it’s our own custom built multi-exabyte infrastructure. After our original migration to Magic Pocket in 2015, our primary goal was to manage large capacity growth at scale. This presented us with challenges including power efficiency and concern for our carbon footprint. We were able to check the box of powering hundreds of millions of users, but we needed to ensure we were being responsible in how we operate. </p>
<p>As we scaled up our team, we started looking past just KTLO (keeping the lights on) toward how to operate more efficiently. After our first year of deployment, we had a bit of sticker shock from our utility bills. We pondered the implication of these high bills not just for Dropbox, but for the environment. Other teams at Dropbox were asking the same questions. Our peers were setting ambitious<a href="https://blog.dropbox.com/topics/company/dropbox-sets-sustainability-goals-for-2030"> </a><a href="https://blog.dropbox.com/topics/company/dropbox-sets-sustainability-goals-for-2030" target="_blank">sustainability goals</a>.</p>
<p>The result was achieving a major milestone in our journey to carbon neutrality: all of our data center storage server power is covered by 100% renewable electricity.</p>
<p>We decided to focus our sustainability efforts on customer data storage because—the <a href="https://www.edelman.com/sites/g/files/aatuss191/files/2021-03/2021%20Edelman%20Trust%20Barometer%20Tech%20Sector%20Report_0.pdf" target="_blank">Edelman 2021 Trust Barometer </a>found that customers are 5.7% more likely to trust companies that embrace sustainable practices. For us there’s a simple metric: You can store all your stuff on Dropbox knowing our data loads are covered by 100% renewable electricity.</p>
<p>We’ve identified three strategies to get to where we are today, and to keep going to even greater sustainability. We’re not here to brag about it—we hope to inspire others to join in bringing real change to the world we share.</p>
<h2>Maximize power usage effectiveness</h2>
<p>Power usage effectiveness (PUE) assesses how efficiently we’re able to leverage the power we consume within our data centers. When we set a goal to achieve best in class PUE, we looked to existing industry benchmarks. In 2015, our PUE was consistent with <a href="https://sustainability.aboutamazon.com/carbon_reduction_aws.pdf" target="_blank">industry averages</a>, but we felt we could do better. </p>
<p>We set out to achieve optimum efficiency through industry best practices throughout our deployments. These strategies include the implementation of outside air economization, thermal containment solutions, and maximizing power utilization through our spaces.</p>
<ul>
<li><b>Outside air economization: </b>in our data centers, hardware needs to be cooled 24/7 because inlet temperatures must be stable to prevent system failure caused by the overheating of components. With outside air economization, our systems bring in outside air at lower temperatures. This reduces the amount of cooling needed to maintain appropriate temperatures. A comparable example would be to think of a hot San Jose apartment: on cool days it makes more sense to open a window to natural cooling than blast the AC—both energy usage and cost are lower. </li>
</ul>
<ul>
<li><b>Thermal containment solutions:</b> Using our window-vs-AC example, when we first moved to Magic Pocket, we cooled entire data centers without taking into account how air could be wasted through leaks or issues with airflow. It’s as if our air conditioner were running on hot days with the window open, letting cooled air escape rather than do its job in the room. We ran a computer fluid dynamics thermal analysis— model to determine where there are air flow inefficiencies that can be fixed. We identified significant opportunities for improvement. We retrofitted existing sites, and made it a standard to include this form of containment in all new data center construction.</li>
</ul>

</div>
<div class="dr-image-container aem-GridColumn aem-GridColumn--default--12">

<div class="dr-image-container__container">
    <div class="dr-image-container__image-container dr-image-container__image-container--2">
        
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-photo-inline.png" alt="DBX containment design" height="963" width="720"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>DBX containment design</p>
</figcaption>
        
    </figure>
</div>
    </div>
    <div class="dr-image-container__image-container dr-image-container__image-container--2">
        
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-color-inline.png" alt="A data module with containment " height="404" width="720"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>A data module with containment </p>
</figcaption>
        
    </figure>
</div>
    </div>
    
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<ul>
<li><b>Maximizing power utilization:</b> Across the industry, data centers are designed to power a specific power range. Any capacity that isn’t used is wasted—at a cost both in dollars and environmental impact. At Dropbox, we aim to reach 85% capacity, a sweet spot for usage that’s efficient yet still gives us extra capacity to handle power spikes.</li>
</ul>
<p>Through these practices we now operate our data centers at a PUE level which is top of class in our industry. By 2020, we were operating at 17% below the <a href="https://journal.uptimeinstitute.com/data-center-pues-flat-since-2013/" target="_blank">industry</a><a href="https://journal.uptimeinstitute.com/data-center-pues-flat-since-2013/" target="_blank"> average</a><a href="https://journal.uptimeinstitute.com/data-center-pues-flat-since-2013/">.</a> In an effort to avoid stagnation, though, we continue our collaboration and solution exploration with current and future data center providers.</p>
<h2>Optimize overall power consumption<br />
</h2>
<p>We don’t just want to use our power more effectively. We want to use <i>less</i> of it. There are several tactics that have let us reduce the energy we use.</p>
<p><b>Quickly power down decommissioned hosts</b></p>
<p>At Dropbox we have a continuous flow of servers that have reached their end of life. As we continued to collect data on our operations, we noticed there was a gap in time between decommissioning hosts and actually powering down the servers. Engineers once manually intervened in most aspects of server maintenance, including provisioning and decommissioning. </p>
<p>To keep from running these unused servers, we leveraged ClusterOps’ <a href="https://dropbox.tech/infrastructure/automating-datacenter-operations-at-dropbox" target="_blank">Pirlo system</a>, originally built to provision servers, to roll out an automation service that powers down a server host immediately after it is decommissioned. This simple change has saved us an estimated 5% in power over each server’s lifespan.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-storage-rack-wattage.png" alt="Storage rack wattage" height="501" width="721"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Storage rack wattage drops in half by switching disk modes from Idle (but still spinning) to HDD Standby</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><b>Leverage a lower power state for servers in our free pool</b></p>
<p>When a server is deployed into Dropbox data centers, it’s first tagged as being available in our free pool. This means the server is sitting online but idle, waiting for one of our services to allocate it for use.</p>
<p>When evaluating a full rack of servers, we saw we were consuming just below 5 kilowatts of power per rack even as it sat idle. We looked for ways to reduce the power consumption of servers not yet in active use.</p>
<p>We’re currently in the process of introducing, a new state in our data centers: <i>HDD Standby</i>. It spins down a server’s disk drives while the operating system is still running, reducing power while still keeping the server alive and available to be identified and allocated to a service. Spinning disk drives use a lot of power. HDD Standby will deliver an estimated 50% power savings on our storage hosts and 25% savings on Hadoop Distributed Filesystem hosts.</p>
<p>Although the savings are substantial, we have come across challenges. Even when hosts are sitting in free pool waiting to be allocated, we still need to monitor the health of all drives, to make sure they can be allocated as needed. Before HDD Standby the drives could respond immediately, since they were already spun up. Now when that query comes in, the server has to wake up the spun down drives, which makes each query take longer. </p>
<p>We can optimize this process, though. Previously we would query drives in series, which means the server would spin up each drive one at a time, check it, then move on to the next. In the last few weeks we’ve pushed code that allows drive queries to be run in parallel. This way all of the drives can be queried and spun back down at the same time. The result is a 99% decrease in time it takes to run a query—time during which most of a server’s disk drives don’t need to be spun up.</p>
<p><b>Rightsizing our capacity</b></p>
<p>There is a fine balance between having enough capacity to mitigate supply / demand risks, such as sudden spikes in traffic caused by regressions or rack delivery delays caused by chip shortages, and having too much idle capacity that makes our system inefficient. </p>
<p>Based on historical data, we’ve built a solid model to determine the right amount of capacity we should have as we go forward. We constantly measure our capacity efficiencies and adjust our supply and demand accordingly.</p>
<p>In previous iterations of Dropbox, capacity planning was done on an annual basis and was decided by historical data and input from service owners. As we’ve expanded the team and expertise, we’ve moved to a monthly planning model, plus we now actively monitor our systems to ensure capacity is being properly used. This enables to build a more reliable model from more data points, which increases accountability and allows for quicker, more nimble pivots in capacity planning.</p>
<p><b>Orchestration</b></p>
<p>We always try to use our hardware to its fullest potential by optimizing all layers of data processing, from <a href="https://dropbox.tech/infrastructure/optimizing-web-servers-for-high-throughput-and-low-latency" target="_blank">hardware and operating systems</a> to <a href="https://dropbox.tech/infrastructure/evaluating-bbrv2-on-the-dropbox-edge-network" target="_blank">TCP congestion protocols</a> and <a href="https://dropbox.tech/infrastructure/-broccoli--syncing-faster-by-syncing-less" target="_blank">compression algorithms</a>. On the data center side, we’re constantly looking at how we can get the maximum use of already-purchased servers through infrastructure-wide improvements. </p>
<p>One of the main initiatives on that front is moving our orchestration platform to <a href="https://kubernetes.io/" target="_blank">Kubernetes</a>. This should give us several major efficiency benefits:</p>
<ul>
<li><a href="https://platform9.com/blog/kubernetes-multi-tenancy-best-practices/#:~:text=Multi%2Dtenant%20Kubernetes%20is%20a,run%20side%2Dby%2Dside.&amp;text=You%20can%20think%20of%20multi,like%20a%20single%2Dfamily%20house." target="_blank"><b>Multi-tenancy.</b></a> Kubernetes’ <a href="https://www.fairwinds.com/blog/5-problems-with-kubernetes-cost-estimation-strategies" target="_blank">bin </a><a href="https://www.fairwinds.com/blog/5-problems-with-kubernetes-cost-estimation-strategies" target="_blank">packing</a> allows us to put multiple services of different shapes (in terms of CPU/memory/network dimensions) on the same server to maximize the overall resource usage.</li>
</ul>
<ul>
<li><a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/node/resource-qos.md" target="_blank"><b>Oversubscription</b></a><b>.</b> In some cases, we can safely overcommit some resource types (e.g. CPU) without degrading the latency of their work. This can improve the efficiency of bursty batch jobs.</li>
</ul>
<ul>
<li><a href="https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/" target="_blank"><b>Background jobs</b></a><b>.</b> Internal “spot instances” can be utilized by low-priority jobs (e.g. data and metadata verifiers). This can lower utilization during peak hours and increase it during idle times, optimizing how much power we need and how effectively we use it.</li>
</ul>
<p>Internally, Dropbox handles around 10x more metadata verification queries than it does queries from users. These queries come from many sources: MySQL replication verifiers (<a href="https://www.percona.com/doc/percona-toolkit/LATEST/pt-table-checksum.html" target="_blank">pt-table-checksum</a>), filesystem verifiers, block verifiers, cold storage verifiers, security verifiers, etc. All of these can benefit from being handled as low-priority job types that maintain steady progress during off-peak hours.</p>
<p><b>Densifying our fleet</b></p>
<p>We continue to evaluate and adopt new hardware—see <a href="https://documents.westerndigital.com/content/dam/doc-library/en_us/assets/public/western-digital/collateral/case-study/case-study-dropbox-magic-pocket-achieves-exabyte-scale-with-smr-hdds.pdf" target="_blank">our case study</a> on Magic Pocket— that packs more capacity into the same space, getting more storage and more processing without adding more servers, more racks, or more rooms of them. This densification—doing more with the same amount of hardware and energy—goes a long way to making our operations more carbon efficient.</p>
<p>Our recently introduced Magic Pocket storage platform uses 20TB drives and offers 43% more storage capacity compared to our previous storage platform. A single storage enclosure can now store over 2PB—up nearly 4x in two generations. </p>
<p>On the compute side, our current platform introduced 48 cores into a single CPU socket, a 3x increase from the previous generation.  </p>
<p>Going forward, hardware makers are developing new technology to continue densification. Hard drive vendors have a roadmap that reaches to 35TB per drive. CPU vendors have announced processors with 128 threads, and are pursuing higher core counts. </p>
<p>Services can be optimized to take advantage of densification by scaling up and/or utilizing multi-tenancy. But even without these additional optimizations. infrastructure compute per watt continues to improve.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-drive-capacities.png" alt="Drive capacities" height="501" width="721"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Drive capacities are increasing with each generation, while their power usage stays flat. The amount of power used for each terabyte has shrunk out of site on this chart.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h1>Source 100% renewable electricity<br />
</h1>
<p>We looked far and wide through our operations to ensure we’re as efficient as possible. We feel confident we’re using industry best practices across the board and are constantly auditing and revisiting our efforts. Moving forward, we want to ensure the energy we need to operate our data centers is renewable, starting with storage. </p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-dashboard.png" alt="This dashboard monitors how much of each type of utility power source is in use across all of our datacenters, with a site-by-site breakdown for each category." height="266" width="720"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>This dashboard monitors how much of each type of utility power source is in use across all of our datacenters, with a site-by-site breakdown for each category.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In 2021, we’re making huge investments to procure renewable energy, as just one of many companies cited in a <a href="https://www.goldmansachs.com/our-commitments/sustainability/sustainable-finance/documents/reports/2020-sustainability-report.pdf" target="_blank">Goldman Sachs report</a> on making all their investments more sustainable. We’ve committed to making the direct power consumption of our storage platform 100% carbon neutral. We’re starting there because we know it’s important to our customers, but it’s important to us, too. </p>
<h2>Results (so far)</h2>
<p>We’ve reduced our datacenter carbon footprint in the last 1.5 years by 15%.  But ensuring the electricity powering our data centers is covered by 100% renewable energy is only the beginning. Because we run a hybrid model, this means working with our public cloud partners, to make sure we meet sustainability goals not just on our own premises, but globally through our partners.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-carbon-footprint.png" alt="Carbon footprint of Dropbox-managed datacenters 2020-2021 " height="301" width="721"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Carbon footprint of Dropbox-managed datacenters 2020-2021 </p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h1>A call to action</h1>
<p>As more companies begin their sustainability journey, we challenge them: Don’t take the easy way out and only look for carbon offsets! We believe that all companies can look internally and find other ways to minimize their carbon footprint in the datacenter space. </p>
<p>Right now, four-fifths of U.S. energy comes from fossil fuels that contribute to climate change. Only a tenth comes from renewable sources. You need to <a href="https://carbonfund.org/difference-carbon-offsets-carbon-credits/" target="_blank">understand that difference</a> between carbon credits (which don’t reduce emissions) and carbon offsets (which do), but all the offsets in the world won’t get us as a planet to where we need to be.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/dc-chart-inline.png" alt="Chart showing U.S. primary energy consumption by energy source, 2019" height="505" width="720"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>This chart needs to change. That will require companies to take risks.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Bill Gates’ new book, <a href="https://www.penguinrandomhouse.com/books/633968/how-to-avoid-a-climate-disaster-by-bill-gates/" target="_blank"><i>How To Avoid A Climate Disaster</i></a>, is worth reading if you’re serious about making the sort of changes we did. He lists ways that even small startups can make differences that add up to a healthier climate: Get the local chamber of commerce to plant trees. Be an early adopter of greener tech, such as our densified racks. Connect with government-funded researchers who don’t have your proven ability to bring their innovations to market. </p>
<p>“Doing only the easy things won’t solve the problem,” Gates writes. “That means accepting more risk … Companies and their leaders need to be rewarded for making bets that could move us forward on climate change.” </p>
<h2><b>We’re hiring!</b></h2>
<p>Interested in helping us build a more efficient supply chain or flexible data center strategy? We’re hiring! Dropbox works <a href="https://blog.dropbox.com/topics/company/dropbox-goes-virtual-first" target="_blank">Virtual First</a>, which means remote rather than office work is the primary experience for <i>all</i> Dropboxers. Join us!</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/Desktop-DC-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/08/data-centers/Desktop-DC-1440x305-light.png" medium="image">
        <media:title type="html">How we’re making Dropbox data centers 100% carbon neutral</media:title>
      </media:content>
    </item>
    <item>
      <title>Sharing our Engineering Career Framework with the world</title>
      <link>https://dropbox.tech/infrastructure/sharing-our-engineering-career-framework-with-the-world</link>
      <dc:creator>Anirudh Todi</dc:creator>
      <category>Infrastructure</category>
      <category>Culture</category>
      <guid>https://dropbox.tech/infrastructure/sharing-our-engineering-career-framework-with-the-world</guid>
      <description><![CDATA[]]></description>
      <pubDate>Mon, 12 Jul 2021 13:00:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>At Dropbox, we strive to be a great place for all engineers to grow and be recognized for that growth. Our Engineering Career Framework helps keep us accountable there and is viewable by anyone within the company. Today, we are also making it <a href="https://dropbox.github.io/dbx-career-framework/" target="_blank">viewable by anyone outside the company</a>. Our goal in doing so is to be transparent externally on how we think about leveling and career progression on the Engineering team at Dropbox. It also enables others to adapt and apply it to their own organizations.</p>
<p>In early 2020, we completed a major revision to the framework. Our focus was to be more explicit about the “what” (i.e. business impact made) and create better representation for all the different crafts within engineering that make Dropbox successful. After a year of running this current version through several promotion cycles, we are satisfied that it is moving our culture in the right direction.</p>
<p>Dropbox’s Engineering Career Framework describes what’s expected for our engineers at each of our career levels. Along with helping managers set expectations and hold teams accountable for their work, this resource empowers engineers to achieve greater impact in their role and grow in their careers.</p>
<p>That said, the framework is not meant to be a promotion checklist; rather, it’s designed to help our engineers know what their impact could look like at the next level. This framework is also not an exhaustive list of examples and behaviors; each responsibility includes three to four key behaviors that serve as a guide for how to think about one’s work. Consequently, it’s worth noting that the framework should not be seen as a replacement for regular, active conversations between engineers and their managers about short and long-term career growth and development.</p>
<p>Teams across our Engineering and People orgs worked together thoughtfully and closely to build this latest version of the Engineering Career Framework. As Dropbox grows and changes, expect it to be a living document that reflects Dropbox’s evolution as an Engineering team.</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/07/Desktop-Making the Dropbox Eng Career Framework-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/07/Desktop-Making the Dropbox Eng Career Framework-1440x305-light.png" medium="image">
        <media:title type="html">Sharing our Engineering Career Framework with the world</media:title>
      </media:content>
    </item>
    <item>
      <title>How we managed our global supply chain through a year of lockdown</title>
      <link>https://dropbox.tech/infrastructure/covid-19-one-year-later</link>
      <dc:creator>Refugio Fernandez</dc:creator>
      <category>data center</category>
      <category>Hardware</category>
      <category>Supply chain</category>
      <category>Infrastructure</category>
      <guid>https://dropbox.tech/infrastructure/covid-19-one-year-later</guid>
      <description><![CDATA[]]></description>
      <pubDate>Thu, 20 May 2021 16:45:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p data-emptytext="Text"></p>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>A little over a year ago, every Dropbox employee received the same email. We were asked to work from home for two weeks to curb the spread of COVID-19. What we didn’t realize then was that a year later, our homes would still be offices and the way we work would have changed permanently.</p>
<p>For the Dropbox Infrastructure team, the March 5 email was no surprise. Our supply chain team had been monitoring the spread of COVID-19 in China and its potential impact on our datacenter hardware suppliers. We documented our initial response to the crisis in a post last April, <a href="https://dropbox.tech/infrastructure/engineering-a-disruption-tolerant-supply-chain">Engineering a disruption tolerant supply chain.</a></p>
<p>Today, we’d like to update that story and report on what the Dropbox infrastructure team has experienced and learned over the last year. By changing the ways we meet with and communicate with our suppliers we’ve been able to keep those relationships alive, stay ahead of new customer demand, build new datacenters while fully remote, and ensure that our supply chain has been minimally disrupted. </p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-learning-to-work-remotely-with-suppliers">
    <h2 class="dr-article-content__section-title"> Learning to work remotely with suppliers</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>When the initial work from home email went out, we immediately moved our supplier meetings to public settings. Even in public settings, the risk to personal health was becoming more evident every day and we would soon stop all in-person meetings.  </p>
<p>The following week, on March 11th, we held what would be our team’s last in-person meeting with our supply base at a local restaurant. No one could imagine what was to come. Dropbox would be one of the first companies to adapt a Virtual First working environment permanently. We would have to change the way we interface with our suppliers. <br />
</p>
<p>In normal circumstances we’d not only meet our suppliers in person on a regular basis, we’d also keep a presence at our supplier’s headquarters and manufacturing sites around the world. We often use the spring, summer, and fall to visit our suppliers in Taiwan, Korea, and Thailand. Locally, we typically visited our suppliers’ rack manufacturing lines on a monthly basis, if not more often. <br />
</p>
<p>The days of the quick in-person coffee or “let’s get business done” lunches were over. Yet the need for dialogue with our suppliers is paramount to Dropbox’s supply chain. We came to adjust by driving high frequency, sometimes high intensity virtual connections with our suppliers. The thinner but more frequent connection with our suppliers have turned out to be the sweet spot for ensuring suppliers are clear on Dropbox’s hardware needs and for ensuring our suppliers are performing. </p>
<p>We found new ways of using Zoom, utilizing it to do virtual manufacturing line walks and quality inspections, both of which we’d normally do in person prior to COVID-19. At first we weren’t very efficient. We found that virtual line walks and quality reviews require preparation with our suppliers ahead of time, both to keep focus on the task at hand and to allow our suppliers to be ready to be Dropbox’s eyes in the factory. In our first few attempts with virtual walk-throughs, we learned the supplier needed time to provide the best camera angles and views of the hardware we were looking at. Getting this right often took many attempts, leading to very long reviews as we allowed for our suppliers to adjust and learn in real time. </p>
<p>Looking back, this shouldn’t have been a surprise to us since the supplier’s core competency is aligned to manufacturing rather than camera work—they’re makers, not influencers.  But together we learned to refine our virtual walk-throughs and can happily say today that we’ve successfully completed many.  </p>
<p>At Dropbox we pride ourselves on the relationships we have established up and down our hardware supply chain. It’s one of the primary means to ensure Dropbox is able to deliver hardware to our growing datacenter footprint. This is especially true given our smaller scale compared to other cloud customers our suppliers serve. The supply chain team knew that communication with our supply base was the only way we could stand a chance to overcome the supply disruption clouds gathering over us. </p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="managing-growing-customer-demand">
    <h2 class="dr-article-content__section-title">Managing growing customer demand</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>At the same time, we promptly let our internal teams know about the looming supply disruptions on the horizon.<i> </i>Our capacity planning team, responsible for forecasting server demand from application owners, began plans for a rise in usage of Dropbox services in anticipation of increased remote work. We kicked off a global scenario planning process to analyze impact to Dropbox’s infrastructure—what will we do if there are supply disruptions due to factory shutdowns, a reduced workforce, and extended lead times as the entire supply chain is affected.</p>
<p>Our playbook was simple: Identify and rank levers that need to be pulled to ensure our availability goals were met, while keeping the lowest possible system cost (trading off between <a href="https://www.investopedia.com/terms/c/capitalexpenditure.asp#:~:text=Capital%20expenditures%20(CapEx)%20are%20funds,or%20investments%20by%20a%20company.">CapEx</a> and <a href="https://www.investopedia.com/terms/o/operating_expense.asp">OpEx</a> while identifying engineering hours spent). </p>
<p>To start, we updated Dropbox’s inventory policy and planning parameters (<a href="https://www.atlassian.com/incident-management/kpis/sla-vs-slo-vs-sli">SLA</a><a href="https://www.atlassian.com/incident-management/kpis/sla-vs-slo-vs-sli">s</a>) to ensure critical infrastructure services like <a href="https://dropbox.tech/infrastructure/inside-the-magic-pocket">Magic Pocket</a> and <a href="https://dropbox.tech/infrastructure/reintroducing-edgestore">Edgestore </a>had enough free capacity to scale if needed. We also started proactively working with application owners to determine an allocation strategy ahead of time for new hardware deliveries—strategic distribution, fair share, first in/first out (FIFO) prioritization. </p>
<p>Finally, to manage short term capacity risks, we identified a set of services which could be migrated to public cloud infrastructure quickly and cost-efficiently. These set of actions helped us stabilize our forecast to suppliers and avoid knee-jerk reactions caused by the <a href="https://supplychain-academy.net/understanding-the-bullwhip-effect-in-supply-chains/">bullwhip effect</a>, in which disruptions travel along the entire chain the way a flick of a whip’s handle causes its tip to lash out painfully at the other end. Migrating to the public cloud isn’t as simple as it might sound, but it offloads both demand growth and unexpected surges to a much larger vendor whose business focus is capacity growth on demand.</p>
<p>These actions ensured that we’d see minimal impact to Dropbox’s capacity <a href="https://www.atlassian.com/incident-management/kpis/sla-vs-slo-vs-sli">SLA/SLO</a>. Most important of all, they ensured no disruption of services to our customers. <br />
</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-maintaining-our-datacenters">
    <h2 class="dr-article-content__section-title"> Maintaining our datacenters</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>While the capacity planning team did its work, the datacenter team focused on three areas; maintaining our physical infrastructure uptime SLAs, keeping our essential staff safe when they have to be onsite, and continuing our planned datacenter expansion timelines.</p>
<p>The first two areas were non-negotiable—Dropbox needed to remain reliable for users, especially as they moved to distributed work for an unknown amount of time, and it was important to keep our team physically healthy. We got eager buy-in from all teams, the key factor in our success at these competing goals.<br />
</p>
<p>We learned some new ways of working. One valuable example: utilizing a rotating skeleton crew with flexible hours proved to be as effective as our normal 9-5 hours with full staffing. It seems counterintuitive, but our crews pulled together to figure out how to make it work.<br />
</p>
<p>We adopted the flextime-skeleton-crew model at all 10 of our datacenter sites with exceptional results. Overall, we tracked government pandemic-safety ordinances across five counties in four states. We partnered closely with our facility managers to ensure Dropbox employees were safe as possible, and that sites had policies in place that aligned with our own company values. In 2020, we kept our <a href="https://en.wikipedia.org/wiki/Service-level_agreement">repair SLAs</a> constant year over year, yet we’re also proud to report no workplace COVID transmission.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="growing-our-datacentersremotely">
    <h2 class="dr-article-content__section-title">Growing our datacenters—remotely</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Building two new datacenter sites in the midst of the pandemic was a new experience for us, and probably for everyone else who builds them. We agreed that the best for Dropbox staff would be to manage the datacenter build completely remote—something we’d never done before. </p>
<p>Software developers take it for granted that an all-remote team can deliver, but would it work for building construction? </p>
<p>We were immediately faced with quality challenges by not having our quality assurance team on site performing weekly job walks. So we shifted our strategy to require construction teams to upload daily or weekly photos (into our Dropbox shared folders of course 🙂). This async visual communication throughout the project, combined with virtual walk-throughs as we did with suppliers, let us identify issues early so we could fix them before they affected schedules.  </p>
<p>We’re happy to report: It works! We were 100% virtual with our onsite construction teams, yet we met our deadlines without sacrificing our state of the art design and quality.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="lessons-from-the-past-year">
    <h2 class="dr-article-content__section-title">Lessons from the past year</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Our first objective across the business was to continue to live out our company value of making work human. We wanted to be reliable partners to everyone from our suppliers to our facility managers. But of course, at the human level everyone was worried about their personal and family well being, and everyone in the supply chain had their own changes to which they needed to adapt.</p>
<p>Over the past year, we realized we needed to be more flexible with our partners, while still ensuring we’re delivering to our customers. This meant changing not only where we work, but how. In some cases it meant swimming upstream in our supply chain to get a better understanding of the level of disruptions happening with our vendors and their suppliers. In others it was changing our mindset about how meetings should work, or bringing <a href="https://blog.dropbox.com/topics/work-culture/what-you-can--and-can-t--learn-from-gitlab-about-remote-work">remote work best practices</a> from software to both hardware manufacturers and the datacenter construction crews.<br />
</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="were-hiring">
    <h2 class="dr-article-content__section-title">We’re hiring</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Interested in helping us build a more resilient supply chain or flexible datacenter strategy? We’re hiring and work Virtual First, which means that remote work (outside an office) will be the primary experience for all Dropboxers. Join us!</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="thank-you">
    <h2 class="dr-article-content__section-title">Thank you</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Thanks to Harish Pushparaj, Chin Lee, and Latane Garetson for helping me capture experiences across Infrastructure.</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/covid-19/headers/Desktop_Infrastructure-Covid-1440x305-Light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/covid-19/headers/Desktop_Infrastructure-Covid-1440x305-Light.png" medium="image">
        <media:title type="html">How we managed our global supply chain through a year of lockdown</media:title>
      </media:content>
    </item>
    <item>
      <title>Optimizing payments with machine learning</title>
      <link>https://dropbox.tech/machine-learning/optimizing-payments-with-machine-learning</link>
      <dc:creator>Sarah Andrabi</dc:creator>
      <category>Machine Learning</category>
      <guid>https://dropbox.tech/machine-learning/optimizing-payments-with-machine-learning</guid>
      <description><![CDATA[]]></description>
      <pubDate>Mon, 17 May 2021 09:52:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>It’s probably happened to you at some point: You go to use a service for which you believe you’ve got a paid subscription, only to find that it’s been canceled for non-payment. That’s not only bad for you the customer: It causes negative feelings about the brand, it disrupts what should be a steady flow of revenue to the business, and a customer who finds themselves shut off might decide not to come back.</p>
<p>At Dropbox, we found that applying machine learning to our handling of customer payments has made us better at keeping subscribers happily humming along.</p>
<p><b>Payments at Dropbox<br />
 </b>The Dropbox Payments Platform manages payment processing for millions of our customers. When a customer visits the Dropbox website and chooses to buy one of our products, we ask the customer to enter their payment information on the purchase form. After the customer submits the form, the system collects their payment information and securely sends this info, along with the amount we want to charge them, to one of our external partners who process that type of payment information.</p>
<p>This all takes place behind the scenes instantly when a customer starts a Dropbox subscription. Once they complete their payment and become a paid customer, they enter our payment lifecycle. All of this, from start to finish, is handled by our Payments Platform.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="subscription-renewals-and-failures">
    <h2 class="dr-article-content__section-title">Subscription renewals and failures</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Customers who have a Dropbox subscription pay for it on a regular cadence—usually monthly or yearly. At the time of a recurring payment, a customer’s credit card is charged automatically (if the customer has authorized us to charge it). If the charge is successful, the subscription is <i>renewed</i> without the customer needing to do anything. </p>
<p>However, if the attempt fails, the customer enters what we call <i>renewal failure</i>. When that happens, we have <i>recovery</i> procedures that attempt to keep the customer’s subscription from being disrupted. </p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/payments-optimization/8rmeuCys.png" alt="" height="800" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Figure 1. Involuntary Churn is when a credit card expires or is canceled, or has no funds, etc.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Historically, our Payments Platform has used a static set of about ten different methods to determine when to charge a customer whose subscription is in renewal failure. For example, we may charge a customer every four days until a payment succeeds, for a maximum of 28 days. If a customer’s payment still fails at the end of this window, their Dropbox account is <a href="https://help.dropbox.com/accounts-billing/cancellations-refunds/downgrade-dropbox-plus-professional-plans#:~:text=When%20you%20downgrade%20to%20a,syncing%20files%20to%20your%20devices.">downgraded</a> to a free Basic account.</p>
<p>Of course, downgrades are a poor customer experience for active users and teams. And involuntary churn can be a lost opportunity for Dropbox.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/payments-optimization/4sLtkY_g.png" alt="" height="620" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Fig 2. Renewal Attempts</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><a href="https://dropbox.tech/infrastructure/handling-system-failures-during-payment-communication">Payment failures</a> can happen for a number of reasons. Among them:</p>
<ul>
<li>insufficient funds</li>
<li>expired credit card</li>
<li>credit card disabled—perhaps reported lost or stolen</li>
<li>transient processing failures</li>
</ul>
<p>Some of these failures can be resolved on their own, while others require customer action for recovery.<br />
</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-why-machine-learning-for-payments">
    <h2 class="dr-article-content__section-title"> Why machine learning for payments?</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In the last couple of years, Dropbox ran <a href="https://en.wikipedia.org/wiki/A/B_testing">A/B tests</a> to see if shifting when we charge customers would have an impact on the success rates of those charges. These A/B tests relied heavily upon human intuition and domain knowledge to come up with a set of rules for when to charge a customer.  </p>
<p>The Payments team had to manually segment users into populations based on their features—subscription type, geographic location, etc—then A/B test our ten or so different hardcoded rule sets to determine which performed the best for those features. The Payments team would then store the best billing policy option as the default for that population. Periodically they would retest to see if the best solutions for different users had changed.<br />
</p>
<p>On the upside, this approach proved that time of charge had an effect on charge success rates, which allowed Dropbox to keep more subscribers humming along without interruption. But over time a large number of these rules have decayed and hit a performance ceiling. Moreover, manually updating these rules is complex and time-consuming. <br />
</p>
<p>In a quest to reduce both involuntary churn and the amount of work required to maintain it, the Payments team partnered with the Applied Machine Learning team to experiment with using machine learning (ML) to optimize billing. <br />
</p>
<p>As a member of the ML team, I knew the challenge is similar to what machine learning experts call the <a href="https://en.m.wikipedia.org/wiki/Multi-armed_bandit">m</a><a href="https://en.m.wikipedia.org/wiki/Multi-armed_bandit">ulti-armed bandit</a> problem—one has a fixed and limited set of resources to allocate among competing alternatives. With payments, we have to determine when to retry, how many times to retry, and whether we should even attempt a retry.<br />
</p>
<p>Applying machine learning over time, we identified multiple improvements that even a team of top Payments experts couldn’t have calculated:</p>
<ul>
<li>Removal of manual intervention and complex rule based logic</li>
<li style="margin-left: 40.0px;">e.g. “Retry every X days” or “Avoid Weekends”</li>
<li>Global optimization of multiple parameters for specific customer segments</li>
<li>Robustness to customer and market changes</li>
<li>An overall increase in payment charge success rates and reduction of collection time</li>
</ul>
<p>In short, applying ML to Payments has made both customers <i>and</i> us happier.<br />
</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-how-we-did-it">
    <h2 class="dr-article-content__section-title"> How we did it</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We began by focusing on predicting when to try charges, i.e. identifying the best time to charge customers<b> </b>at the time of subscription renewal, and to retry charging their account during renewal failure. </p>
<p>We experimented with different customer segments, specifically starting with Individual customers and teams in North America. We built a <a href="https://en.wikipedia.org/wiki/Gradient_boosting">gradient boosted</a> <a href="https://en.wikipedia.org/wiki/Learning_to_rank">ranking</a> model trained with features including types of payment failures, Dropbox account usage patterns, and payment type characteristics. The model ranks the charge attempts by predicted likelihood of success for each charge window. <br />
</p>
<p>For example, we took an 8 day window and divided it into one-hour chunks, resulting in a total of 192 time chunks. We used our models to find the highest ranking time chunk to attempt the renewal. We also experimented with 6- and 4- day windows. <br />
</p>
<p>At first, we experimented with optimizing each charge attempt independently. We had a model that optimized when to charge a customer after the first payment failed. If the model’s recommended attempt also failed, we defaulted back to our rule-based logic for the rest of the renewal window. We ran an A/B test for this combination, using a random sampling of the US individual user segments. For targeting we used our internal feature gating service, <a href="https://dropbox.tech/infrastructure/introducing-stormcrow"><u>Stormcrow</u></a>. The model improved success rates, and we shipped it.  <br />
</p>
<p>Our goal was always end-to-end optimization of renewal failure attempts. Starting with a single model helped validate that ML could be applied to solve this type of problem. However, we realized quickly that this design pattern of having a separate model per payment attempt only created a more complicated system. For example, if we retried 5 times before a payment succeeded, using this design we would end up with 5 models. This went against our secondary goal of using ML to reduce the complexity of the billing system.<br />
</p>
<p>So we shifted our approach to have a single model that can predict when to charge a customer multiple times until the customer is able to successfully renew, or is downgraded after the maximum renewal window has passed as in Figure 2.  If the first payment failed, we’d ask the model for the next best time to charge. If that failed, we’d again ask the model for the next best time, and so on for a maximum number of times. At that point, if none of the payments have succeeded, the customer is downgraded. But if any of the payments succeeded, the associated invoice was approved no matter how many payment attempts had been made. <br />
</p>
<p>This specific model is currently being A/B tested in production, using our <a href="https://dropbox.tech/infrastructure/introducing-stormcrow"><u>Stormcrow</u></a> system to randomly target Dropbox teams for testing. The results so far are positive.<br />
</p>
<p><b>Serving predictions<br />
 </b>Once we had trained models, our next step was to make these models available during payments processing. We needed a way to serve the best time to charge predictions from our machine learning models to the <a href="https://dropbox.tech/infrastructure/handling-system-failures-during-payment-communication">Payments Platform</a>, ensuring they would be used as part of the billing policy. </p>
<p>When we first began experimentation, we were using the Payments Platform to load and run the model. This design caused the Payments Platform to bloat significantly due to the added dependencies. Prediction latencies ran to around two minutes on average. </p>
<p>To streamline the process, we took advantage of the Predict Service built and managed by the ML Platform team, which manages the infrastructure to help quickly build, deploy and scale machine learning processes at Dropbox. Using Predict Service helped reduce latency for generating model predictions from several minutes to under 300ms for 99 percent of them. Migrating to Predict Service also provided a clean separation between the two systems, and the ability to scale easily.<br />
</p>
<p>With this plug-and-play machine learning system, the Payments Platform fetches all the signals relevant to a customer and makes a request to the model (served via Predict Service) to get the best time to charge the customer, eliminating all of our old hardcoded sub-optimal billing policies developed over 14 years of A/B testing.<br />
</p>
<p>The workflow for this system is designed as follows. White represents components of the Payments Platform. Purple represents components of the machine learning system.<br />
</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/payments-optimization/mIvZnTPk.png" alt="" height="938" width="720"/>

    

            
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<ol>
<li><b>Get prediction for next time to charge — </b>When a payment attempt for a customer fails, the payments platform makes a request to the <b><i>predict</i></b> module to get the next best time to charge the customer. The request is made using the <i>customer id </i>and<i> type.</i></li>
<li><b>Retrieve customer signals.</b> The <b><i>predict</i></b> module collects the most recent usage and payments signals for customers, as well as information about the previous failure. This data is stored in <a href="https://dropbox.tech/infrastructure/reintroducing-edgestore">Edgestore</a> (the primary metadata storage system at Dropbox) using a daily scheduled <a href="https://airflow.apache.org/docs/apache-airflow/stable/index.html">Airflow Job</a>.</li>
<li><b>Request prediction</b> — The collected signals are sent to <b>Predict Service</b> via a <a href="https://dropbox.tech/infrastructure/courier-dropbox-migration-to-grpc">GRPC</a> call, which encodes the signals into a feature dataframe and then sends them to the model.</li>
<li><b>Generate prediction — </b>The model returns the best ranked time for when to charge the customer. This prediction is sent back to the <b>predict</b> module, which returns the results to the billing policy.</li>
<li><b>Log prediction results</b> — The <b>predict</b> module also logs the model’s prediction, along with other relevant information that can be used for troubleshooting and analysis.</li>
<li><b>Schedule next charge</b> — Once the payments service receives the best time to charge, it then uses it to schedule the next payment attempt, and stores that in <a href="https://dropbox.tech/infrastructure/reintroducing-edgestore">Edgestore</a>.</li>
</ol>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-ml-operations">
    <h2 class="dr-article-content__section-title"> ML Operations</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Our task wasn’t done upon rollout. We applied DevOps best practices to our data collection and prediction systems: We automated our data collection jobs to run daily, and put monitoring in place to notify us of any failures or delays in the jobs running. </p>
<p>For our models and model-serving infrastructure we defined a set of business- and model-specific metrics that we track, and set up alerting in case any metrics go below an acceptable threshold. These are the main metrics and measures we use to ensure that everything is running as expected:<br />
</p>
<p><b>Business Metrics</b></p>
<ul>
<li><b>Invoice Approval Rate</b>: This is the primary metric that we want to improve. Every time a user’s Dropbox subscription renews, all the payments for that specific renewal are tracked as part of a single invoice. This metric tells us whether the renewal for the user was successful or not.</li>
<li><b>Attempt Success Rate</b>: This metric helps us track the success rates for each individual payment attempt made on behalf of the user. There might be one payment attempt made, or two, four, or more. This metric, along with the Invoice Approval Rate<i>,</i> helps us track how quickly we are able to renew a customer.</li>
</ul>
<p><b>Model internal monitoring <br />
 </b>This is a set of measures internal to the training process and tooling being used. These help us determine how well the model is tuned based on the input data, as well as helping to identify any issues with the model while it’s running in production. We measure the following online model metrics to help with diagnostics:</p>
<ul>
<li><b>Coverage</b>: the percentage of customers that have recommendations from the model compared to the fixed 4 day interval.</li>
<li><b>Number of predictions made by the model: </b>the number of recommendations that the model made successfully without any errors</li>
<li><b>Prediction Latency</b>: how long it took the model to make each recommendation</li>
</ul>
<p><b>Infrastructure monitoring<br />
 </b>Along with all the monitoring and alerting in place for Payments Platform and Predict Service, we also track the following to track how well our infrastructure is performing:</p>
<ul>
<li>Freshness and delays in feature data pipelines</li>
<li>Availability and latency of Predict Service</li>
<li>Availability of EdgeStore</li>
</ul>
<p>We use <a href="https://en.wikipedia.org/wiki/Grafana">Grafana</a> dashboards and <a href="https://dropbox.tech/infrastructure/monitoring-server-applications-with-vortex">Vortex</a> for monitoring our model, and infrastructure metrics. For business metrics we use <a href="https://dropbox.tech/application/why-we-chose-apache-superset-as-our-data-exploration-platform">Superset</a>. All these live metrics, and dashboards help us proactively track the expected behavior of the model, enabling us to take appropriate action when it <a href="https://dropbox.tech/infrastructure/lessons-learned-in-incident-management">deviates</a>. </p>
<p>The responsibility of monitoring these metrics is split between the Payments engineering team and the Applied Machine Learning team. We have troubleshooting guides to help on-call engineers to debug any issues with clear escalation paths. Since ML was new to the Payments engineering team, we spent time explaining how the systems worked, and how to interpret the model’s results. This has helped the two teams successfully collaborate on the project and ensure that everything runs smoothly.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="next-steps">
    <h2 class="dr-article-content__section-title">Next steps</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Our experimentation has validated that the ML-based system outperforms our rule-based approach. Moreover, without manual and extensive investment, the rule-based system’s performance will decay over time, whereas the ML system stays sharp through retraining. We can further improve the models by adding more relevant features, and experimenting with different model architectures. </p>
<p>Our model targeting individual customers is currently deployed in production. Our model for optimizing the entire renewal cycle is currently running in A/B testing. We’re looking towards expanding our model optimizations from North America to all customers across the globe. There are also more complex model types that we can experiment with—including reinforcement learning—now that we have the data and production pipelines built. As we improve our models, we’ll focus on further improvements to our renewal success rates that will keep customers happy as well.</p>
<p><b>We're hiring!</b><br />
The Applied Machine Learning team and ML Platform team at Dropbox use Machine Learning (ML) to drive outsized business and user value by leveraging a high-fidelity understanding of users, content, and context. We work closely with other product and engineering teams to deliver innovative solutions and features. It’s exciting to find opportunities within Dropbox to improve our processes and customer experiences by applying ML to new fields. We plan to continue to use the lessons from this project and apply them to other areas.</p>
<p>The Payments team at Dropbox enables monetization of new and existing products via a flexible payments and collections system and a smooth user experience. We leverage Machine Learning(ML) to optimize our billing and routing systems. We are also actively experimenting with ML based strategies for targeted payments and billing communications. In addition to directly impacting revenue these ML based approaches improve the productivity of the team and maintainability of our systems.</p>
<p>See open positions at Dropbox <a href="https://www.dropbox.com/jobs/all-jobs"><u>here</u></a>! </p>
<p><b>Thanks to: <br />
 </b>The Payments Engineering, Product, Revenue Analytics, and ML Platform teams for their continued partnership. In particular: Pratik Agrawal, Kirill Sapchuk, Cameron (Cam) Moten, Bryan Fong, Randy Lee, Yi Zhong, Anar Alimov, Aleksandr Livshits, Lakshmi Kumar T, Evgeny Skarbovsky and Ian Baker.</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/payments-optimization/MachineLearning-PaymentOptimization-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/payments-optimization/MachineLearning-PaymentOptimization-1440x305-light.png" medium="image">
        <media:title type="html">Optimizing payments with machine learning</media:title>
      </media:content>
    </item>
    <item>
      <title>How image search works at Dropbox</title>
      <link>https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox</link>
      <dc:creator>Thomas Berg</dc:creator>
      <category>Machine Learning</category>
      <guid>https://dropbox.tech/machine-learning/how-image-search-works-at-dropbox</guid>
      <description><![CDATA[]]></description>
      <pubDate>Tue, 11 May 2021 10:40:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Photos are among the most common types of files in Dropbox, but searching for them by filename is even less productive than it is for text-based files.  When you're looking for that photo from a picnic a few years ago, you surely don't remember that the filename set by your camera was <i>2017-07-04 12.37.54.jpg</i>.  </p>
<p>Instead, you look at individual photos, or thumbnails of them, and try to identify objects or aspects that match what you’re searching for—whether that’s to recover a photo you’ve stored, or perhaps discover the perfect shot for a new campaign in your company’s archives.  Wouldn’t it be great if Dropbox could pore through all those images for you instead, and call out those which best match a few descriptive words that you dictated? That’s pretty much what our <a href="https://help.dropbox.com/files-folders/sort-preview/image-search">image search</a> does.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/xx_yrSW-.png" alt="" height="473" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Image content search results for “picnic”</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In this post we’ll describe the core idea behind our image content search method, based on techniques from machine learning, then discuss how we built a performant implementation on Dropbox’s existing search infrastructure.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="our-approach">
    <h2 class="dr-article-content__section-title">Our approach</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Here’s a simple way to state the image search problem: find a <i>relevance function</i> that takes a (text) query <i>q</i> and an image <i>j</i>, and returns a relevance score <i>s</i> indicating how well the image matches the query.</p>
<p><i>s = f(q, j)</i></p>
<p>Given this function, when a user does a search we run it on all their images and return those that produce a score above a threshold, sorted by their scores.  We build this function using two key developments in machine learning: accurate <i>image classification</i> and <i>word vectors</i>.</p>
<p><b>Image classification<br />
 </b>An <i>image classifier</i> reads an image and outputs a scored list of categories that describe its contents. Higher scores indicate a higher probability that the image belongs to that category.  </p>
<p>Categories can be:</p>
<ul>
<li>specific objects in the image, such as <i>tree</i> or <i>person</i></li>
<li>overall scene descriptors like <i>outdoors</i> or <i>wedding</i></li>
<li>characteristics of the image itself, such as <i>black-and-white</i> or <i>close-up</i></li>
</ul>
<p>The past decade has seen tremendous progress in image classification using convolutional neural networks, beginning with <a href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">Krizhevsky </a><a href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html"><i>et al</i></a><a href="https://proceedings.neurips.cc/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html">’s breakthrough result</a> on the ImageNet challenge in 2012. Since then, with model architecture improvements, better training methods, large datasets like <a href="https://storage.googleapis.com/openimages/web/index.html">Open Images</a> or <a href="http://image-net.org/">ImageNet</a>, and easy-to-use libraries like <a href="https://www.tensorflow.org/">TensorFlow</a> and <a href="https://pytorch.org/">PyTorch</a>, researchers have built image classifiers that can recognize thousands of categories.</p>
<p>Take a look at how well image classification works today:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/NZT1drfj.png" alt="" height="318" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Image classifier outputs for a typical unstaged photo</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Image classification lets us automatically understand what’s in an image, but by itself this isn’t enough to enable search. Sure, if a user searches for <i>beach</i> we could return the images with the highest scores for that category, but what if they instead search for <i>shore</i>? What if instead of apple they search for <i>fruit</i> or <i>granny smith</i>?</p>
<p>We could collate a large dictionary of synonyms and near-synonyms and hierarchical relationships between words, but this quickly becomes unwieldy, especially if we support multiple languages.</p>
<p><b>Word vectors</b><br />
So let’s reframe the problem. We can interpret the output of the image classifier as a vector <i><b>j<sub>c</sub></b></i> of the per-category scores. This vector represents the content of the image as a point in <i>C</i>-dimensional category space, where <i>C</i> is the number of categories (several thousand). If we can extract a meaningful representation of the query in this space, we can interpret how close the image vector is to the query vector as a measure of how well the image matches the query.</p>
<p>Fortunately, extracting vector representations of text is the focus of a great deal of research in natural language processing. One of the best known methods in this area is described in Mikolov et al’s 2013 word2vec paper. Word2vec assigns a vector to each word in the dictionary, such that words with similar meanings will have vectors that are close to each other. These vectors are in a <i>d</i>-dimensional word vector space, where d is typically a few hundred.</p>
<p>We can get a vector representation of a search query simply by looking up its word2vec vector. This vector is not in the category space of the image classifier vectors, but we can transform it into category space by referencing the names of the image categories as follows:</p>
<ol>
<li>For query word <i>q</i>, get the <i>d</i>-dimensional word vector <b>q<sub>w</sub></b>, normalized to a unit vector. We’ll use a <b>w</b> subscript for vectors in word space and a <b>c</b> subscript for vectors in category space.</li>
<li>For each category, get the normalized word vector for the category name<b> c<sup>i</sup><sub>w</sub></b>. Then define <i>m̂<sup>i</sup></i> =<b> q<sub>w</sub> · c<sup>i</sup><sub>w</sub></b>, the cosine similarity between the query vector and the <i>i</i>-th category vector. This score between -1 and 1 indicates how well the query word matches the category name. By clipping negative values to zero, so that <i>m<sup>i</sup></i> = max(0, <i>m̂<sup>i</sup></i>), we get a score in the same range as the image classifier outputs.</li>
<li>This lets us calculate <b>q<sub>c</sub></b> = [<i>m<sup>1</sup> m<sup>2</sup> ... m<sup>C</sup></i>], a vector in the <i>C</i>-dimensional category space which represents how well the query matches each category, just as the image classifier vector for each image represents how well the image matches each category.</li>
</ol>
<p>Step 3 is just a vector-matrix multiplication, <b>q<sub>c</sub></b> = <b>q<sub>w</sub>C</b>, where <b>C</b> is the matrix whose columns are the category word vectors <b>c<sup>i</sup><sub>w</sub></b>.</p>
<p>Once we've mapped the query to category space vector <b>q<sub>c</sub></b>, we can take its cosine similarity with the category space vector for each image to get a final relevance score for the image, <i>s</i> = <b>q<sub>c</sub>j<sub>c</sub></b>.</p>
<p>This is our relevance function, and we rank images by this score to show the results of the query. Application of this function to a set of images can also be expressed as a vector-matrix multiplication, <b>s</b> = <b>q<sub>c</sub>J</b>, where each column of <b>J</b> is the classifier output vector <b>j<sub>c</sub></b> for an image and <b>s</b> is the vector of relevance scores for all images.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="an-example">
    <h2 class="dr-article-content__section-title">An example</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Let’s go through an example with only a few dimensions, where word vectors have only three dimensions and the classifier has only four categories: <i>apple</i>, <i>beach</i>, <i>blanket</i>, and <i>dog</i>.</p>
<p>Suppose a user has searched for shore.  We look up the word vector to get [0.35 -0.62 0.70], then multiply by the matrix of category word vectors to project the query into category space.</p>
<p>Because the shore word vector is close to the beach word vector, this projection has a large value in the <i>beach</i> category.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/veZNQZbt.png" alt="" height="289" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Projecting a query word vector into category space</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><b>Modeling details<br />
 </b>Our image classifier is an <a href="http://proceedings.mlr.press/v97/tan19a.html">EfficientNet network</a> trained on the <a href="https://storage.googleapis.com/openimages/web/index.html">OpenImages dataset</a>.  It produces scores for about 8500 categories.  We’ve found that this architecture and dataset give good accuracy at a reasonable cost, which matters if we want to serve a Dropbox-sized customer base.</p>
<p>We use TensorFlow to train and run the model.  We use the pre-trained <a href="https://github.com/commonsense/conceptnet-numberbatch">ConceptNet Numberbatch</a> word vectors. These give good results, and importantly to us they support multiple languages, returning similar vectors for words in different languages with similar meanings.  This makes supporting image content search in multiple languages easy: word vectors for <i>dog</i> in English and <i>chien</i> in French are similar, so we can support search in both languages without having to perform an explicit translation.</p>
<p>For multi-word searches, we parse the query as an AND of the individual words.  We also maintain a list of multi-word terms like <i>beach ball</i> that can be considered as single words.  When a query contains one of these terms we do an alternate parse and run the OR of the two parsed queries—the query <i>beach ball</i> becomes <span class="dr-code">(beach AND ball) OR (beach ball)</span>. This will match both large, colorful, inflatable balls and tennis balls in the sand.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="production-architecture">
    <h2 class="dr-article-content__section-title">Production architecture</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>It’s not practical to fetch a full, up-to-date <b>J</b> matrix whenever a user does a search.  A user may have access to hundreds of thousands or even millions of images, and our classifier outputs are thousands of dimensions, so this matrix could have billions of entries and needs to be updated whenever a user adds, deletes, or modifies an image. This simply won’t scale affordably (yet) for hundreds of millions of users.</p>
<p>So instead of instantiating <b>J</b> for each query, we use an approximation of the method described above, one which can be implemented efficiently on Dropbox’s <a href="https://dropbox.tech/machine-learning/architecture-of-nautilus-the-new-dropbox-search-engine">Nautilus</a> search engine.</p>
<p>Conceptually, Nautilus consists of a forward index that maps each file to some metadata (e.g. the filename) and the full text of the file, and an inverted index that maps each word to a <i>posting list</i> of all the files that contain the word. For text-based search, the index content for a few recipe files might look something like this:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/w7RFa4Y_.png" alt="" height="248" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Search index contents for text-based search</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>If a user searches for <i>white wine</i>, we look up the two words in the inverted index and find that <i>doc_1</i> and <i>doc_2</i> have both words, so we should include them in the search results. <i>Doc_3</i> has only one of the words, so we should either leave it out or put it last in the results list. </p>
<p>Once we've found all the documents we may want to return, we look them up in the forward index and use the information there to rank and filter them. In this case, we might rank <i>doc_1</i> higher than <i>doc_2</i> because the two words occur right next to each other.</p>
<p><b>Repurposing text search methods for image search<br />
 </b>We can use this same system to implement our image search algorithm.  In the forward index, we can store the category space vector <b>j</b><sub><b>c</b></sub><b> </b>of each image.  In the inverted index, for each category, we store a posting list of images with positive scores for that category.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/MEda8mit.png" alt="" height="265" width="720"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Search index contents for image content search</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>So, when a user searches for <i>picnic</i>:</p>
<ol>
<li>Look up the word vector <b>q<sub>w</sub></b> for <i>picnic</i> and multiply by the category space projection matrix <b>C</b> to get <b>q<sub>c</sub></b> as described above.  <b>C</b> is a fixed matrix that’s the same for all users, so we can hold it in memory.</li>
<li>For each category with a nonzero entry in <b>q<sub>c</sub></b>, fetch the posting list from the inverted index. The union of these lists is the search result set of matching images, but these results still need to be ranked.</li>
<li>For each search result, fetch the category space vector <b>j<sub>c</sub></b> from the forward index and multiply by <b>q<sub>c</sub></b> to get the relevance score <i>s</i>. Return results with score above a threshold, ranked by the score.</li>
</ol>
<p><b>Optimizing for scalability<br />
 </b>This approach is still expensive both in terms of storage space and in query-time processing.  If we have 10,000 categories, then for each image we have to store 10,000 classifier scores in the forward index, at a cost of 40 kilobytes if we use four-byte floating point values.  And because the classifier scores are rarely zero, a typical image will be added to most of those 10,000 posting lists. If we use four-byte integers for the image ids, that’s another 40 kilobytes, for an indexing cost of 80 kilobytes per image.  For many images, the index storage would be larger than the image file!</p>
<p>As for query-time processing — which appears as latency to the user performing the search — we can expect about half of the query-category match scores <i>m̂<sup>i</sup></i> to be positive, so we’ll read about 5,000 posting lists from the inverted index.  This compares very poorly with text queries, which typically read about ten posting lists.</p>
<p>Fortunately, there are a lot of near-zero values that we can drop to get a much more efficient approximation.  The relevance score for each image was given above as <i>s</i> = <b>q<sub>c</sub>j<sub>c</sub></b>, where <b>q<sub>c</sub></b> holds the match scores between the query and each of the roughly 10,000 categories, and <b>j<sub>c</sub></b> holds the roughly 10,000 category scores from the classifier. Both vectors consist of mostly near-zero values that make very little contribution to <i>s</i>.  </p>
<p>In our approximation, we’ll set all but the largest few entries of <b>q<sub>c</sub></b> and <b>j<sub>c</sub></b> to zero.  Experimentally we’ve found that keeping the top 10 entries of <b>q<sub>c</sub></b> and top 50 entries of <b>j<sub>c</sub></b> is enough to prevent a degradation in quality. The storage and processing savings are substantial:</p>
<ul>
<li>In the forward index instead of 10,000-dimensional dense vectors we store <a href="https://en.wikipedia.org/wiki/Sparse_matrix">sparse vectors</a> with 50 nonzero entries — the top 50 category scores for each image.  In a sparse representation we store the position and value of each nonzero entry; 50 two-byte integer positions and 50 four-byte float values requires about 300 bytes.</li>
<li>In the inverted index, each image is added to 50 posting lists instead of 10,000, at a cost of about 200 bytes.  So the total index storage per image is 500 bytes instead of 80 kilobytes.</li>
<li>At query time, <b>q<sub>c</sub></b> has 10 nonzero entries, so we only need to scan 10 posting lists — roughly the same amount of work we do for text queries.  This gives us a smaller result set, which we can score more quickly as well.</li>
</ul>
<p>With these optimizations, indexing and storage costs are reasonable, and query latencies are on par with those for text search.  So when a user initiates a search we can run both text and image searches in parallel, and show the full set of results together, without making the user wait any longer than they would for a text-only search.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="current-deployment">
    <h2 class="dr-article-content__section-title">Current deployment</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Image content search is currently enabled for all of our Professional and Business level users. We combine image content search for general images, <a href="https://dropbox.tech/machine-learning/using-machine-learning-to-index-text-from-billions-of-images">OCR-based search for images of documents</a>, and <a href="https://dropbox.tech/infrastructure/firefly-instant-full-text-search-engine">full-text search for text documents</a> to make most of these users' files available through content-based search.</p>
<p><b>Video search?<br />
 </b>Of course, we’re working to let you search <i>all</i> of your Dropbox content. Image search is a big step toward that. Eventually, we hope to be able to search video content as well. The techniques to <a href="http://whichframe.com/">find one frame</a> in a video, or to <a href="https://deepai.org/publication/frozen-in-time-a-joint-video-and-image-encoder-for-end-to-end-retrieval">index an entire clip for searching</a>, perhaps by <a href="https://arxiv.org/abs/2104.08860">adapting still image techniques</a>, are still at the research stage, but it was just a few years ago that “find all the photos from my picnic with my dog in them” only worked in Hollywood movies.</p>
<p>Our goal is: If it’s in your Dropbox, we’ll find it for you!<br />
</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/headers/BKFAqwdi.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/05/image-search/headers/BKFAqwdi.png" medium="image">
        <media:title type="html">How image search works at Dropbox</media:title>
      </media:content>
    </item>
    <item>
      <title>Boosting Dropbox upload speed and improving Windows’ TCP stack</title>
      <link>https://dropbox.tech/infrastructure/boosting-dropbox-upload-speed</link>
      <dc:creator>Alexey Ivanov and Dzmitry Markovich</dc:creator>
      <category>Infrastructure</category>
      <category>Edge Network</category>
      <guid>https://dropbox.tech/infrastructure/boosting-dropbox-upload-speed</guid>
      <description><![CDATA[]]></description>
      <pubDate>Mon, 03 May 2021 10:53:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>One of the best ways to find ways to improve performance, we’ve found, is to work closely with our customers. We love shared troubleshooting sessions with their own engineering teams to find and eliminate bottlenecks. </p>
<p>In one of these, we found a discrepancy in upload speeds between Windows and Linux. We then worked with the <a href="https://techcommunity.microsoft.com/t5/networking-blog/algorithmic-improvements-boost-tcp-performance-on-the-internet/ba-p/2347061">Windows Core TCP team</a> to triage the problem, find workarounds, and eventually fix it. The issue turned out to be in the interaction between the Windows TCP stack and firmware on the Network Interface Controllers (NIC) we use on our Edge servers.</p>
<p>As a result, Microsoft improved the Windows implementation of the TCP RACK-TLP algorithm and its resilience to packet reordering. This is now fixed and available starting with Windows 10 build 21332 through the Windows Insider Program dev channel.</p>
<p>How we got there is an interesting and instructive tale—we learned that Windows has some tracing tools beyond our Linux-centric experience, and working with Microsoft engineers led to both a quick workaround for our users and a long-term fix from Microsoft. Teamwork! We hope our story inspires others to collaborate across companies to improve their own users’ experiences.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-what-users-dont-know-dropbox-does-for-them">
    <h2 class="dr-article-content__section-title"> What users don’t know Dropbox does for them</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Dropbox is used by many creative studios, including video and game productions. These studios’ workflows frequently use offices in different time zones to ensure continuous progress around the clock. The workloads of such studios are usually characterized by their extreme geographic distribution and the need for very fast uploads/downloads of large files. </p>
<p>All of this is usually done without any specialized software, using a Dropbox Desktop Client. The hardware used for these transfers varies widely: Some studios use dedicated servers with 10G internet connectivity, while others simply rely on thousands of MacBooks with normal Wi-Fi connectivity.</p>
<p>On one hand, Dropbox Desktop Client has just a few settings. On the other, behind this simple UI lies some pretty sophisticated Rust code with multi-threaded compression, chunking, and hashing. On the lowest layers, it is backed up by HTTP/2 and TLS stacks. </p>
<p>The outer simplicity of Dropbox Desktop Client can be quite misleading, though. Balancing performance with resource consumption across heterogeneous hardware and different use-cases is quite tricky:</p>
<ul>
<li><span style="">If we push compression too much, </span><a href="https://dropbox.tech/infrastructure/-broccoli--syncing-faster-by-syncing-less">we starve upload threads on 10G servers</a><span style="">. But if we pull it another way we waste bandwidth on slow internet connections.</span></li>
<li>If we increase the number of hashing threads to speed up server uploads, laptop users suffer CPU/memory usage, which can cause their laptops to heat up.</li>
<li>If we improve the performance of hashing code, it can cause high iowait on spinning disks.</li>
</ul>
<p>With so many different scenarios for optimization we try to understand each customer’s set of bottlenecks and make Dropbox Client adapt to its environment automatically, as opposed to bloating settings with a myriad of tunables.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-how-we-spotted-the-problem">
    <h2 class="dr-article-content__section-title"> How we spotted the problem</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>While doing routine performance troubleshooting for a customer we noticed slow upload speeds. As usual, our network engineers promptly established peering with the customer. This improved latencies a lot, but upload speed was still bogged down to a few hundred megabits per host—fast enough for most people, but too slow if you work with giant files all day.</p>
<ul>
<p>Shameless plug: Dropbox has an <a href="https://www.dropbox.com/peering">open peering policy</a>. If you need a more direct path and lower packet loss, <a href="https://www.peeringdb.com/asn/19679">please peer with us</a>!</p>
</ul>
<p>Looking into the problem, we noticed that only Windows users were affected. Both macOS and Linux could upload at the network’s line rate. We set up a testing stand in the nearest cloud provider and began to drill down on Windows usage in a controlled environment. </p>
<p>For us, as primarily Linux backend engineers, this was an interesting experience and learning opportunity. We started at the application layer with an <a href="http://www.rohitab.com/apimonitor">API Monitor</a>, a fairly sophisticated <span class="dr-code">strace/ltrace</span> analog for Windows.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/e5LK8ZSI.png" alt="API Monitor for Windows" height="860" width="1600"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>API Monitor for Windows</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Our hypothesis was that we might be “app limited”, i.e. there was not enough data being held in the socket buffer, which could cause upload speed to be limited. But we quickly saw this was not the case. Instead, the application was waiting on IOCP events from the kernel. This usually indicates bottlenecks at the TCP level.</p>
<p>Now on familiar territory to us, we jumped into Wireshark. It immediately identified long periods of upload inactivity, in which the client’s machine was waiting for ACKs from the Dropbox side with a minuscule ~200kb of inflight data:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/4KOIvH_w.png" height="293" width="1600"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Wireshark: sender waits for 21ms (rtt) ACKs. Then immediately sends a new batch of segments.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>But <a href="https://packetbomb.com/understanding-the-tcptrace-time-sequence-graph-in-wireshark/#:~:text=The%20Time%2DSequence%20graph%20shows,data%20flowing%20in%20one%20direction.">Wireshark’s </a><a href="https://packetbomb.com/understanding-the-tcptrace-time-sequence-graph-in-wireshark/#:~:text=The%20Time%2DSequence%20graph%20shows,data%20flowing%20in%20one%20direction."><span class="dr-code">tcptrace</span></a><a href="https://packetbomb.com/understanding-the-tcptrace-time-sequence-graph-in-wireshark/#:~:text=The%20Time%2DSequence%20graph%20shows,data%20flowing%20in%20one%20direction."> analog</a> showed that bytes in flight were not limited by the receive window size.  This meant there was likely something inside the sending side’s TCP stack preventing it from growing its congestion window:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/aPCzUsJQ.png" alt="Note the gaps between blue lines (outgoing segment runs) and the distance to green line (receive window)" height="852" width="1600"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Note the gaps between blue lines (outgoing segment runs) and the distance to green line (receive window)</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>With this information, it was time to contact the Windows Core TCP Team to start digging into it together.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="debugging-with-microsoft">
    <h2 class="dr-article-content__section-title">Debugging with Microsoft</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The first thing Microsoft engineers suggested was to switch from our UNIX-y way of collecting packet dumps to a Windows-friendly way of doing the same thing:</p>
<p><code><span class="dr-code">&gt; netsh trace start provider=Microsoft-Windows-TCPIP capture=yes packettruncatebytes=120 tracefile=net.etl report=disabled perf=no</span></code></p>
<p style="margin-left: 40.0px;">There is also a tool called etl2pcapng that converts <span class="dr-code">etl</span> files to <span class="dr-code">pcap</span>. This lets you do in-depth packet analysis in Wireshark/<span class="dr-code">tshark</span>.</p>
<p>This was an eye-opening experience for us. We saw how far behind Linux is on the tracing tooling side. Even with all advances on the eBPF front, there’s still no unified format in Linux for collecting traces across all kernel subsystems. <span class="dr-code">tcpdump</span> is an awesome tool, but it only provides insight into what’s happening on the wire—it can’t connect that to other kernel events.</p>
<p><span class="dr-code">netsh trace</span>, on the other hand, correlates events on the wire with events that happen on the TCP layer, timers, buffer management, socket layer, and even the Windows asyncio subsystem (IOCP).</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Ep8abCck.png" alt="Microsoft Message Analyzer parsing netsh trace output. Imagine a combination of tcpdump, perf trace, strace, and ss." height="1000" width="1600"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Microsoft Message Analyzer parsing netsh trace output. Imagine a combination of tcpdump, perf trace, strace, and ss.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Message Analyzer allowed us to dig deeper and confirm our theory of small congestion windows. (Sadly, <a href="https://docs.microsoft.com/en-us/openspecs/blog/ms-winintbloglp/dd98b93c-0a75-4eb0-b92e-e760c502394f">Microsoft Message Analyzer has since been retired</a>, likely due to performance issues it had. Microsoft now advises to use <span class="dr-code"><a href="https://docs.microsoft.com/en-us/windows-server/networking/technologies/pktmon/pktmon">pktmon</a></span> to analyze logs along with packet dumps.)</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="we-find-packet-reordering">
    <h2 class="dr-article-content__section-title">We find packet reordering</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>At that point Microsoft engineers also suggested we look into packet reordering that was present on the link:</p>
<p><code>&gt; tshark -r http2-single-stream.pcapng &quot;tcp.options.sack_le &lt; tcp.ack&quot; | find /c /v &quot;&quot; 131</code></p>
<p>They explained: </p>
<ul>
<p>This filter is not direct evidence of packet reordering. It filters for DSACKs which likely indicates reordering because it tends to cause spurious retransmissions. If a system already has reordering resilience, this filter is not true anymore.</p>
</ul>
<p>Now the ball was on the Dropbox side to find where the reordering was introduced. Based on the SACKs observed in packet captures, it clearly happened somewhere before traffic hit our edge L7LBs (<a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">we</a><a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy"> use Envoy</a>). Comparing the (mirrored) traffic on L4LBs (we use <a href="https://github.com/facebookincubator/katran">katran</a>, an eBPF/XDP-based horizontally scalable, high-performance load balancer) to the traffic between L4LBs and L7LBs it became apparent that reordering happened somewhere there. We saw a reordering event for a single flow happening every 1-10 seconds.</p>
<p>Nowadays, Windows is using CUBIC congestion control, just like Linux does by default. To get to <a href="https://tools.ietf.org/html/rfc8312#section-5.2">10 Gbps over 100ms RTT a loss-based CUBIC needs &lt;0.000003% packet loss</a>. So even a tiny amount of perceived packet loss might greatly affect the performance. </p>
<p>Microsoft engineers also explained:</p>
<ul>
<p>At the same time, traditionally, <a href="https://tools.ietf.org/html/rfc5681#section-3.2">TCP used the</a><a href="https://tools.ietf.org/html/rfc5681#section-3.2"> </a><a href="https://tools.ietf.org/html/rfc5681#section-3.2">“3</a><a href="https://tools.ietf.org/html/rfc5681#section-3.2"> duplicate ACK” heuristic</a> which meant that any reordering in the network of degree 3 or more in number of packets is perceived as loss.</p>
</ul>
<p>After an approximate reordering location was identified we went through layer by layer, looking at each for an entity that could potentially reorder packets. We didn’t need to go far. First, we started by ruling out obvious stuff like network flapping and problems with the ECMP load-balancing. </p>
<p>Then system engineers looked at our sufficiently sophisticated network cards, which could potentially reorder packets (at least from an OS point of view). This is a side-effect of an Intel NICs feature called “<a href="https://www.kernel.org/doc/html/latest/networking/device_drivers/ethernet/intel/i40e.html#application-targeted-routing-atr-perfect-filters">Application</a><a href="https://www.kernel.org/doc/html/latest/networking/device_drivers/ethernet/intel/i40e.html#application-targeted-routing-atr-perfect-filters"> Targeted Routing</a><a href="https://www.kernel.org/doc/html/latest/networking/device_drivers/ethernet/intel/i40e.html#application-targeted-routing-atr-perfect-filters"> </a><a href="https://www.kernel.org/doc/html/latest/networking/device_drivers/ethernet/intel/i40e.html#application-targeted-routing-atr-perfect-filters">(ATR)</a>.” In theory, this feature should <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/intel-ethernet-flow-director.pdf">reduce CPU usage by directing packets to the CPU that currently owns processing of that TCP flow</a>, therefore, reducing cache misses. In practice, this may cause the OS to think that there is a reordering on the link. </p>
<p>Especially severe reordering happens when a flow director’s filter table overflows and gets forcefully flushed:</p>
<p><code><span class="dr-code-container__pre">$ ethtool -S eth0 | fgrep fdir<br />
 </span></code><code><span class="dr-code-container__pre">  port.fdir_flush_cnt: 409776<br />
 </span></code><code><span class="dr-code-container__pre">  port.fdir_atr_match: 2090843606356</span></code></p>
<p>It turns out that this is a known issue discussed in academic research papers (see Appendix A below).</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-choosing-a-workaround">
    <h2 class="dr-article-content__section-title"> Choosing a workaround</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We considered a couple of alternative solutions to this problem:</p>
<ul>
<li><b>Pin proxy threads to CPUs. </b>This, combined with <a href="https://gist.github.com/SaveTheRbtz/8875474">IRQ pinning</a> and <a href="https://www.kernel.org/doc/html/latest/networking/scaling.html#xps-transmit-packet-steering">XPS</a>, should eliminate threads jumping from one core to another, removing the possibility of reordering. This is an ideal solution, but it would require quite a bit of engineering effort and rollout. We held off on this option unless we got closer to our CPU utilization limits on the Edge throughout the next couple of years.</li>
<li><b>Reconfigure FlowDirector.</b> 10G Intel NICs (<span class="dr-code">ixgbe</span>) used to have a <span class="dr-code">FdirPballoc</span> parameter that allowed changing the amount of memory that FlowDirector could use. But it’s not present in either <span class="dr-code">i40e</span> docs or <a href="https://elixir.bootlin.com/linux/latest/source/Documentation/networking/device_drivers/ethernet/intel/ixgbe.rst" style="background-color: rgb(255,255,255);">newer kernel versions for </a><a href="https://elixir.bootlin.com/linux/latest/source/Documentation/networking/device_drivers/ethernet/intel/ixgbe.rst" style="background-color: rgb(255,255,255);"><span class="dr-code">ixgbe</span></a>. We quickly lost interest in this path, so we didn’t go full “kernel-archeologist” on it to find out what had happened to this tunable.</li>
<li><b>Just turn ATR off.</b> Since we don’t rely on it in any way, we decided to go with this approach.</li>
</ul>
<p>We used ethtool’s “priv flags” machinery to turn ATR off</p>
<p><code># ethtool --set-priv-flags eth0 flow-director-atr off</code></p>
<p>Note that different drivers/firmwares would likely have a totally different set of flags there. In this example, <span class="dr-code">flow-director-atr</span> is specific to Intel i40e NICs.</p>
<p>After applying the change to a single PoP, server-side packet reordering immediately went down:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Techblog-UploadSpeed-720x93px-1.png" height="186" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Here we use the “Challenge ACK” rate as a proxy for the incoming reordering, since this is what we send to the client when data doesn’t arrive in order.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>On the client side, the Windows platform overall upload speed immediately went up proportionally:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Techblog-UploadSpeed-720x94px-2.png" alt="This is the Week-over-Week ratio for average per-chunk upload speeds." height="188" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>This is the Week-over-Week ratio for average per-chunk upload speeds.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>As a follow up we also began tracking our Desktop Client upload/download performance on a per-platform basis. Rolling out the fix across the whole Dropbox Edge Network brought up Windows upload speeds to be on par with macOS:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Techblog-UploadSpeed-720x224px-3.png" height="448" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p style="text-align: center;"><i>Linux upload speeds here are not representative. The large portion of Linux hosts are servers with dozens of CPUs, RAIDs, and 1+Gbit/s Internet connections.</i></p>
</figcaption>
        
    </figure>
</div></div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="microsofts-long-term-fix">
    <h2 class="dr-article-content__section-title">Microsoft’s long-term fix</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>This was the end of the story for us, but the Windows Core TCP team started work on adding reordering resilience to the Windows TCP RACK implementation. This concluded recently with the Windows 10 build 21332. It fully implements the recently published Standards Track RFC “<a href="https://www.rfc-editor.org/rfc/rfc8985.html">RFC</a><a href="https://www.rfc-editor.org/rfc/rfc8985.html"> 8985: The RACK-TLP Loss Detection Algorithm for TCP</a>,” including the reordering heuristic. This heuristic upgrades TCP to be resilient to up to a round-trip-time worth of packet reordering in the network.</p>
<p>In theory, one can see that <a href="https://www.rfc-editor.org/rfc/rfc8985.html#name-reordering-design-rationale">the rationale for the reordering heuristic</a> covers our Flow-Director side-effect. One of the Microsoft team explained:</p>
<ul>
<p>“Upon receiving an ACK indicating a SACKed segment, a sender cannot tell immediately whether that was a result of reordering or loss. It can only distinguish between the two in hindsight if the missing sequence ranges are filled in later without retransmission. Thus, a loss detection algorithm needs to budget some wait time -- a reordering window -- to try to disambiguate packet reordering from packet loss.“</p>
</ul>
<p>In practice, we reran our tests with the newest available Windows 10 build (10.0.21343.1000) against a single PoP, while toggling ATR on and off. We didn’t observe any upload performance degradation.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="acknowledgments">
    <h2 class="dr-article-content__section-title">Acknowledgments</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Even though this specific issue was very deep in our infrastructure network stack, troubleshooting it required work from multiple teams from both Dropbox and Microsoft sides:</p>
<ul>
<li>Dropbox Networking: Amit Chudasma.</li>
<li>Dropbox Desktop Client Sync Engine Team: Geoffry Song, John Lai, and Joshua Warner.</li>
<li>Microsoft Core TCP Team: Matt Olson, Praveen Balasubramanian, and Yi Huang.</li>
<li>… and of course all our customers’ engineers who participated in our shared performance improvement sessions!</li>
</ul>

</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><b>Update (5/11/2021):</b> For more on recent Windows TCP performance improvements, including HyStart++, Proportional Rate Reduction, and RACK-TLP, read <a href="https://techcommunity.microsoft.com/t5/networking-blog/algorithmic-improvements-boost-tcp-performance-on-the-internet/ba-p/2347061">“Algorithmic improvements boost TCP performance on the Internet”</a>, a blogpost published by Microsoft’s TCP Dev team. It goes deeper into the theory behind these TCP features and provides benchmarks for TCP performance under different conditions.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/aPoxV6d8.png" alt="" height="763" width="1528"/>

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Microsoft’s benchmarks for TCP reordering resilience before and after the full RACK-TLP implementation.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="appendix-a-academic-research">
    <h2 class="dr-article-content__section-title">Appendix A. Academic research</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We were not the first to stumble upon this problem. Once we identified the culprit and started doing research, we found that it’s a known problem in HPC clusters. For example, here are a couple of excerpts from the paper, “<a href="https://arxiv.org/pdf/1106.0443.pdf">Why</a><a href="https://arxiv.org/pdf/1106.0443.pdf"> Does Flow Director Cause Packet Reordering?</a>” by <a href="https://www.fnal.gov/">Fermilab</a>:</p>

</div>
<div class="dr-image-container aem-GridColumn aem-GridColumn--default--12">

<div class="dr-image-container__container">
    <div class="dr-image-container__image-container dr-image-container__image-container--2">
        
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

            
        
    </figure>
</div>
    </div>
    <div class="dr-image-container__image-container dr-image-container__image-container--2">
        
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

            
        
    </figure>
</div>
    </div>
    
</div></div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/appendixa3.png" alt="" height="378" width="927"/>

    

            
        
    </figure>
</div></div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Infrastructure-UploadSpeed-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/04/boosting-dropbox-upload/Infrastructure-UploadSpeed-1440x305-light.png" medium="image">
        <media:title type="html">Boosting Dropbox upload speed and improving Windows’ TCP stack</media:title>
      </media:content>
    </item>
    <item>
      <title>Detecting memory leaks in Android applications</title>
      <link>https://dropbox.tech/mobile/detecting-memory-leaks-in-android-applications</link>
      <dc:creator>Lily Chen</dc:creator>
      <category>Android</category>
      <category>Performance</category>
      <category>Application</category>
      <guid>https://dropbox.tech/mobile/detecting-memory-leaks-in-android-applications</guid>
      <description><![CDATA[]]></description>
      <pubDate>Tue, 23 Mar 2021 10:00:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Memory leaks occur when an application allocates memory for an object, but then fails to release the memory when the object is no longer being used. Over time, leaked memory accumulates and results in poor app performance and even crashes. Leaks can happen in any program and on any platform, but they’re especially prevalent in Android apps due to complications with <a href="https://developer.android.com/guide/components/activities/activity-lifecycle">activity </a><a href="https://developer.android.com/guide/components/activities/activity-lifecycle">lifecycles</a>. Recent Android patterns such as <a href="https://developer.android.com/topic/libraries/architecture/viewmodel"><span class="dr-code">ViewModel</span></a> and <a href="https://developer.android.com/reference/androidx/lifecycle/LifecycleObserver"><span class="dr-code">LifecycleObserver</span></a> can help avoid memory leaks, but if you’re following older patterns or don’t know what to look out for, it’s easy to let mistakes slip through.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-common-examples">
    <h2 class="dr-article-content__section-title"> Common examples</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h3>Reference to a long-lived service</h3>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/diagrams/Techblog-AndroidMemoryLeaks-720x485px-1-r.png" alt="diagram showing fragment view that references a long-lived service" height="970" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>A fragment references an activity which references a long-lived service.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In this case, we have a standard setup with an activity that holds a reference to some long-living service, then a fragment and its view that hold references to the activity. For example, say that the activity somehow creates a reference to its child fragment. Then, for as long as the activity sticks around, the fragment will continue living too. This causes a leak for the duration between the fragment’s <span class="dr-code">onDestroy</span> and the activity’s <span class="dr-code">onDestroy</span>.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/diagrams/Techblog-AndroidMemoryLeaks-720x485px-2-r.png" alt="diagram showing memory leak caused by fragment referencing a long-lived service" height="970" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>The fragment will never be used again, yet it persists in memory.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h3>Long-lived service which references a fragment’s view</h3>
<p>What if, in the other direction, the service obtained a reference to the fragment’s view? First, the view would now stay alive for the entire duration of the service. Furthermore, because the view holds a reference to its parent activity, the activity now leaks as well.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/diagrams/Techblog-AndroidMemoryLeaks-720x486px-3-r.png" alt="diagram showing memory leak in long-lived service that references a fragment view" height="972" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>As long as the Service lives, the FragmentView and Activity will squander memory.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-detecting-memory-leaks">
    <h2 class="dr-article-content__section-title"> Detecting memory leaks</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Now that we know how memory leaks happen, let’s discuss what we can do to detect them. An obvious first step is to check if your app ever crashes due to <span class="dr-code">OutOfMemoryError</span>. Unless there’s a single screen that eats more memory than your phone has available, you have a memory leak somewhere.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/screenshot-1.png" alt="app crashes due to OutOfMemoryError" height="144" width="922"/>
        

    

            
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>This approach only tells you the existence of the problem—not the root cause. The memory leak could have happened anywhere, and the crash that’s logged doesn’t point to the leak, only to the screen that finally tipped memory usage over the limit. </p>
<p>You could inspect all the breadcrumbs to see if there’s some similarity, but chances are the culprit won’t be easy to discern. Let’s explore other options.</p>
<h3>LeakCanary</h3>
<p>One of the best tools out there is <a href="https://square.github.io/leakcanary/#:~:text=LeakCanary%20is%20a%20memory%20leak,developers%20dramatically%20reduce%20OutOfMemoryError%20crashes.">LeakCanary</a>, a memory leak detection library for Android. We simply <a href="https://square.github.io/leakcanary/getting_started/">add a dependency on our build.gradle file</a>. The next time we install and run our app, LeakCanary will be running alongside it. As we navigate through our app, LeakCanary will pause occasionally to dump the memory and provide leak traces of detected leaks.</p>
<p>This one step is vastly better than what we had before. But the process is still manual, and each developer will only have a local copy of the memory leaks they’ve personally encountered. We can do better!</p>
<h3>LeakCanary and Bugsnag </h3>
<p>LeakCanary provides a very handy <a href="https://square.github.io/leakcanary/recipes/#uploading-to-bugsnag">code recipe</a> for uploading found leaks to <a href="https://www.bugsnag.com/">Bugsnag</a>. We’re then able to track memory leaks just as we do any other warning or crash in the app. We can even take this one step further and use <a href="https://www.bugsnag.com/integrations">Bugsnag’s integrations </a>to hook it up to project management software such as Jira for even more visibility and accountability.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/screenshot-2.png" alt="screenshot showing BugSnag integration with Jira" height="552" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Bugsnag connected to Jira</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h3>LeakCanary and integration tests</h3>
<p>Another way to improve automation is to hook up LeakCanary to CI tests. Again, we are given a <a href="https://square.github.io/leakcanary/recipes/#running-leakcanary-in-instrumentation-tests">code recipe</a> to start with. From the official documentation: </p>
<p style="margin-left: 40.0px;"><i>LeakCanary provides an artifact dedicated to detecting leaks in UI tests which provides a run listener that waits for the end of a test, and if the test succeeds then it looks for retained objects, trigger a heap dump if needed and perform an analysis.</i></p>
<p>Be aware that LeakCanary will slow down testing, as it dumps the heap after each test to which it listens. In our case, because of our <a href="https://dropbox.tech/mobile/revamping-the-android-testing-pipeline-at-dropbox">selective testing and sharding set up</a>, the extra time added is negligible. </p>
<p>Our end result is that memory leaks are surfaced just as any other build or test failure on CI, with the leak trace at the time of the leak recorded.</p>
<p>Running LeakCanary on CI has helped us learn better coding patterns, especially when it comes to new libraries, before any code hits production. For example, it caught this leak when we were working with <a href="https://github.com/airbnb/mavericks">MvRx</a> mocks: </p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">&lt;failure&gt;Test failed because application memory leaks were detected: ==================================== HEAP ANALYSIS RESULT ==================================== 4 APPLICATION LEAKS References underlined with &quot;~~~&quot; are likely causes. Learn more at https://squ.re/leaks. 198449 bytes retained by leaking objects Signature: 6bf2ba80511dcb6ab9697257143e3071fca4 ┬─── 
│ GC Root: System class 
│ ├─ com.airbnb.mvrx.mocking.MockableMavericks class 
│ Leaking: NO (a class is never leaking) 
│ ↓ static MockableMavericks.mockStateHolder 
│                            ~~~~~~~~~~~~~~~ 
├─ com.airbnb.mvrx.mocking.MockStateHolder instance 
│ Leaking: UNKNOWN 
│ ↓ MockStateHolder.delegateInfoMap 
│                   ~~~~~~~~~~~~~~~ 
├─ java.util.LinkedHashMap instance 
│ Leaking: UNKNOWN 
│ ↓ LinkedHashMap.header 
│                 ~~~~~~ 
├─ java.util.LinkedHashMap$LinkedEntry instance 
│ Leaking: UNKNOWN 
│ ↓ LinkedHashMap$LinkedEntry.prv 
│                             ~~~ 
├─ java.util.LinkedHashMap$LinkedEntry instance 
│ Leaking: UNKNOWN 
│ ↓ LinkedHashMap$LinkedEntry.key 
│                             ~~~ 
╰→ com.dropbox.product.android.dbapp.photos.ui.view.PhotosFragment instance 
   Leaking: YES (ObjectWatcher was watching this because com.dropbox.product.android.dbapp.photos.ui.view.PhotosFragment received Fragment#onDestroy() callback and Fragment#mFragmentManager is null) 
   key = 391c9051-ad2c-4282-9279-d7df13d205c3 
   watchDurationMillis = 7304 
   retainedDurationMillis = 2304 198427 bytes retained by leaking objects 
   Signature: d1c9f9707034dd15604d8f2e63ff3bf3ecb61f8</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>It turned out that we hadn’t properly cleaned up the mocks when writing the test. Adding a few lines of code avoids the leak:</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">   @After
    fun teardown() {
        scenario.close()
        val holder = MockableMavericks.mockStateHolder
        holder.clearAllMocks()
    }</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>You may be wondering: Since this memory leak only happens in tests, is it really that important to fix? Well, that’s up to you! Like linters, leak detection can tell you when there’s <a href="https://en.wikipedia.org/wiki/Code_smell">code smell</a> or bad <a href="https://en.wikipedia.org/wiki/Software_design_pattern">coding patterns</a>. It can help teach engineers to write more robust code—in this case, we learned about the existence of <span class="dr-code">clearAllMocks()</span>. The severity of a leak and whether or not it’s imperative to fix are decisions an engineer can make.</p>
<p>For tests on which we don’t want to run leak detection, we wrote a simple annotation:</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">@Retention(RetentionPolicy.RUNTIME)
@Target({ElementType.METHOD, ElementType.TYPE})
public @interface SkipLeakDetection {
    /**
     * The reason why the test should skip leak detection.
     */
    String value();
}</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>and in our class which overrides LeakCanary’s <span class="dr-code">FailOnLeakRunListener()</span>:</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">override fun skipLeakDetectionReason(description: Description): String? {
    return when {
        description.getAnnotation(SkipLeakDetection::class.java) != null -&gt;
            &quot;is annotated with @SkipLeakDetection&quot;
        description.testClass.isAnnotationPresent(SkipLeakDetection::class.java) -&gt;
            &quot;class is annotated with @SkipLeakDetection&quot;
        else -&gt; null
    }
}</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Individual tests or entire test classes can use this annotation to skip leak detection.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-fixing-memory-leaks">
    <h2 class="dr-article-content__section-title"> Fixing memory leaks</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Now that we’ve gone over various ways to find and surface memory leaks, let’s talk about how to actually understand and fix them. </p>
<p>The leak trace provided by LeakCanary will be the single most useful tool for diagnosing a leak. Essentially, the leak trace prints out a chain of references associated with the leaked object, and provides an explanation of why it’s considered a leak. </p>
<p>LeakCanary already has <a href="https://square.github.io/leakcanary/fundamentals-fixing-a-memory-leak/">great documentation</a> on how to read and use its leak trace, so there’s no need to repeat it here. Instead, let’s go over two categories of memory leaks that I mostly found myself dealing with.</p>
<h3>Views</h3>
<p>It’s common to see views declared as class level variables in fragments: <span class="dr-code">private TextView myTextView</span>;  or, now that more Android code is being written in <a href="https://kotlinlang.org/">Kotlin</a>: <span class="dr-code">private lateinit var myTextView: TextView</span>—common enough for us not to realize that these can all cause memory leaks. </p>
<p>Unless these fields are nulled out in the fragment’s <span class="dr-code">onDestroyView</span>, (which you can’t do for a <span class="dr-code">lateinit</span> variable), the references to the views now live for the duration of the fragment’s lifecycle, and not the fragment’s view lifecycle as they should. </p>
<ul>
<p><i>The simplest scenario of how this causes a leak: We are on FragmentA. We navigate to FragmentB, and now FragmentA is on the back stack. FragmentA is not destroyed, but FragmentA’s view is destroyed. Any views that are tied to FragmentA’s lifecycle are now held in memory when they don’t need to be.</i></p>
</ul>
<p>For the most part, these leaks are small enough to not cause any performance issues or crashes. But for views that hold objects and data, images, view/data binding and the like, we are more likely to run into trouble. </p>
<p>So when possible, avoid storing views in class-level variables, or be sure to clean them up properly in <span class="dr-code">onDestroyView</span>.</p>
<p>Speaking of view/data binding, <a href="https://developer.android.com/topic/libraries/view-binding">Android’s view binding documentation</a> tells us exactly that: the field must be cleared to prevent leaks. Their code snippet recommends we do the following: </p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">private var _binding: ResultProfileBinding? = null
// This property is only valid between onCreateView and
// onDestroyView.
private val binding get() = _binding!!

override fun onCreateView(inflater: LayoutInflater, container: ViewGroup?, savedInstanceState: Bundle?
): View? {
    _binding = ResultProfileBinding.inflate(inflater, container, false)
    val view = binding.root
    return view
}

override fun onDestroyView() {
    super.onDestroyView()
    _binding = null
}</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>This is lot of boilerplate to put in every fragment (also, avoid using <a href="https://stackoverflow.com/questions/34342413/what-is-the-kotlin-double-bang-operator">!!</a> which will throw a <span class="dr-code">KotlinNullPointerException</span> if the variable is null. Use explicit null handling instead.) We addressed this issue is by creating a <span class="dr-code">ViewBindingHolder</span> (and <span class="dr-code">DataBindingHolder</span>) that fragments can then implement:</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 java">interface ViewBindingHolder&lt;B : ViewBinding&gt; {

    var binding: B?

    // Only valid between onCreateView and onDestroyView.
    fun requireBinding() = checkNotNull(binding)

    fun requireBinding(lambda: (B) -&gt; Unit) {
        binding?.let {
            lambda(it)
        }}

    /**
     * Make sure to use this with Fragment.viewLifecycleOwner
     */
    fun registerBinding(binding: B, lifecycleOwner: LifecycleOwner) {
        this.binding = binding
        lifecycleOwner.lifecycle.addObserver(object : DefaultLifecycleObserver {
            override fun onDestroy(owner: LifecycleOwner) {
                owner.lifecycle.removeObserver(this)
                this@ViewBindingHolder.binding = null
            }
        })
    }
}

interface DataBindingHolder&lt;B : ViewDataBinding&gt; : ViewBindingHolder&lt;B&gt;</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>This provides an easy and clean way for fragments to:</p>
<ul>
<li>Ensure binding is present when it’s required</li>
<li>Only execute certain code if the binding is available</li>
<li>Clean up binding on <span class="dr-code">onDestroyView</span> automatically</li>
</ul>
<h3>Temporal leaks</h3>
<p>These are leaks that only stick around for a short duration of time. In particular, one that we ran into was caused by an <span class="dr-code">EditTextView</span>'s async task. The async task lasted just longer than LeakCanary’s default wait time, so a leak was reported even though the memory was cleaned up properly soon afterward. </p>
<p>If you suspect you are running into a temporal leak, a good way to check is to use Android Studio’s <a href="https://developer.android.com/studio/profile/memory-profiler">memory profiler.</a> Once you start a session within the profiler, take the steps to reproduce the leak, but wait for a longer period of time before dumping the heap and inspecting. The leak may be gone after the extra time.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/screenshot-3.png" height="742" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Android Studio’s memory profiler shows the effect of temporal leaks that get cleaned up.</p>
</figcaption>
        
    </figure>
</div></div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-test-often-fix-early">
    <h2 class="dr-article-content__section-title"> Test often, fix early</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We hope that with this overview, you’ll feel empowered to track down and tackle memory leaks in your own application! Like many bugs and other issues, it’s much better to test often and fix early before a bad pattern gets deeply baked into the codebase. As a developer, it’s important to remember that while memory leaks may not always affect your own app performance, users with lower-end models and lower-memory phones will appreciate the work you’ve done on their behalf. Happy leak hunting!</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/headers/Mobile-AndroidMemoryLeaks-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/03/android-memory-leaks/headers/Mobile-AndroidMemoryLeaks-1440x305-light.png" medium="image">
        <media:title type="html">Detecting memory leaks in Android applications</media:title>
      </media:content>
    </item>
    <item>
      <title>Automating contract management with Dropbox and Integromat</title>
      <link>https://dropbox.tech/developers/automating-contract-management-dbx-integromat</link>
      <dc:creator>Tahsin Islam</dc:creator>
      <category>Workflow</category>
      <category>Automation</category>
      <category>Partners</category>
      <category>Developer Spotlight</category>
      <guid>https://dropbox.tech/developers/automating-contract-management-dbx-integromat</guid>
      <description><![CDATA[Learn how to automate workflows like contract management with Integromat’s new Dropbox integration]]></description>
      <pubDate>Wed, 17 Mar 2021 09:30:00 -0700</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><a href="https://www.integromat.com/?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><i><u>Integromat</u></i></a><i> is a powerful integration platform to connect apps and automate workflows in just a few clicks. Featuring 600+ apps and 6,000+ endpoints, Integromat is redefining work automation so everyone can get back to what matters the most. </i></p>
<p><i>We asked </i><a href="https://www.linkedin.com/in/jessica-herauf-31852383/"><i><u>Jessica Herauf</u></i></a><i>, Head of App Partnerships at Integromat, to write a guest post on our developer blog, and share how to accelerate digital paperwork workflows involving digital signature tools, CRMs, and Dropbox. </i></p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="what-is-integromat">
    <h2 class="dr-article-content__section-title">What is Integromat?</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Integromat is the <a href="https://www.integromat.com/?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>app integration platform</u></a> that allows anyone to create powerful integrations and automate tasks. Integromat users range from independent professionals and small businesses to organizations like Spotify, Facebook, and the United Nations. </p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  align-center">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-signup-page.png" alt="Sign up page for Integromat" height="581" width="1135"/>
        

    

            
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Users can pick from a selection of 600+ apps to automate both simple and complex tasks using Integromat’s drag and drop visual builder. The platform integrates directly with app APIs, and this of course includes the <a href="https://www.integromat.com/en/integrations/dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>Dropbox API</u></a>, for which Integromat currently features 14 endpoints or “modules”. </p>
<p>Integromat modules allow you to connect Dropbox to hundreds of different apps and automate tasks like:</p>
<ul>
<li>Uploading and downloading files</li>
<li>Sharing and moving files between folders</li>
<li>Creating file share links</li>
</ul>
<p>Tasks like these are often part of collaborative processes, involving teams that need to increase productivity and bring down costs. </p>
<p>With Integromat, users can create their own Dropbox integrations from scratch, or else rely on available <a href="https://www.integromat.com/en/templates/dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>templates</u></a> to automate tasks like:</p>
<ul>
<li><u><a href="https://www.integromat.com/en/integration/3093-save-new-telegram-files-to-dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post">Saving new Telegram files to Dropbox</a></u></li>
<li><u style="background-color: rgb(255,255,255);"><a href="https://www.integromat.com/en/integration/286-upload-new-dropbox-files-to-slack?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post" style="background-color: rgb(255,255,255);">Uploading new Dropbox files to a Slack channel or conversation</a></u></li>
<li><a href="https://www.integromat.com/en/integration/2503-backup-new-google-photos-to-dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post" style="background-color: rgb(255,255,255);"><u>Backing up Google Photos to Dropbox</u></a></li>
</ul>
<p>Below, we will show you how to use Dropbox and Integromat to automate a task that affects an entire industry. </p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="leveraging-dropbox-and-integromat-to-create-an-automated-contract-management-system">
    <h2 class="dr-article-content__section-title">Leveraging Dropbox and Integromat to create an automated contract management system</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The real estate industry is fertile ground for automation. Regular industry procedures like sales, valuations, and leases demand paperwork, which in turn require time and resources. </p>
<p>A good example of this paperwork can be found within contracts. By automating contract management tasks, companies can increase their opportunities and revenues. </p>
<p>As you can foresee, Integromat and Dropbox can lay the foundation for a contract management automation solution that scales. You will get the best of contract management software, without having to onboard one. </p>
<p>Let’s say you are a real estate agent that just closed a sale and need to create, store, and send a contract to your client (or to an attorney) to get it signed and successfully finish the operation. </p>
<p>In other words, a normal contracting process, which can take anywhere from several hours to a few days to be completed when done the traditional way. In turn, it adds costs and risk to what is perhaps the most sensitive stage of a real estate sale. </p>
<p>With this in mind, we developed an automated solution that will allow you to:</p>
<ul>
<li>Reduce the duration of the process to a matter of minutes</li>
<li>Bring down costs </li>
<li>Lower the risk levels attached to late contract arrivals </li>
</ul>
<p>Additionally, we are making this automated contract management solution <a href="https://www.integromat.com/en/integration/4796-hubspot-google-docs-dropbox-contract-management?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>available as an Integromat template</u></a>. In order to access and use it, you will need an Integromat account. In case you don’t have one yet, please <a href="https://www.integromat.com/en/register?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>sign up for free</u></a>.  </p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-workflow.png" alt="Contract management workflow template" height="435" width="863"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Contract management workflow template<br />
</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Now, back to our use case. </p>
<p>The picture above shows the contract management workflow template. It features the tasks/actions that Integromat will automatically complete for you on a recurring basis. These actions are:</p>
<ul>
<li>Watch records/deals on HubSpot CRM</li>
<li>Create a contract from a Google doc template</li>
<li>Download the contract to Google Drive</li>
<li>Send the contract via Gmail to the corresponding recipient</li>
<li>Upload a copy of the contract to Dropbox </li>
</ul>
<p>It all begins with HubSpot CRM for a simple reason: in many cases, the need for a contract starts within a customer relationship management (CRM) platform, which is what several real estate professionals use to manage and close property sales.  </p>
<p>Taking this into account, we chose HubSpot - one of the most popular CRMs out there - as the first module of our template. In case you don’t use HubSpot, Integromat features <a href="https://www.integromat.com/en/integrations#filter:crm?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>28 other CRMs</u></a> you can select to replace the first module.    </p>
<p>This module will trigger the whole automated sequence by performing an elementary task: watching your HubSpot records for deals. Whenever a deal gets marked or labeled as “closed”, Integromat will trigger the subsequent steps in the sequence. </p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  align-center">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-hubspot-config.png" alt="Hubspot module configuration" height="832" width="628"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Hubspot module configuration<br />
</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The second step demands special attention. Here, Integromat will automatically create a contract from a Google doc template, using the data from the corresponding HubSpot record/deal to fill in the details. </p>
<p><i>Note: the </i><a href="https://www.integromat.com/en/integration/4796-hubspot-google-docs-dropbox-contract-management"><i><u>Integromat template page</u></i></a><i> provides a contract template, but feel free to modify it or use your own Google doc template, as this will be the document Integromat will use to generate, send, and store your future contracts. </i></p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  align-center">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-google-config.png" alt="Google Docs module configuration" height="1314" width="683"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Google Docs module configuration<br />
</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>After the contract is created, Integromat will download/store it in a dedicated folder within your Google Drive account. This is the third action. </p>
<p>Once this is done, Integromat will do the following:</p>
<ul>
<li>Store a copy of the contract in a dedicated Dropbox folder</li>
<li>Send a copy of the contract via Gmail to the recipient you want (including yourself)</li>
</ul>
<p>To do this, Gmail and Dropbox modules are placed to pick up the recipient’s email address from the corresponding HubSpot record. See the details of each module below.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-dropbox-config.png" height="1088" width="655"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>“Send an email” Gmail module configuration</p>
</figcaption>
        
    </figure>
</div></div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-dropbox-file-save.png" height="479" width="384"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>“Upload a file” Dropbox module configuration</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>And that’s it! After this, please save and run the scenario to see how it works. A trial run with one contract produced the following results.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-email-confirmation.png" alt="An email message with a contract attached" height="520" width="1291"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Email message with contract attached</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Plus, a copy of that same contract, stored in a dedicated Dropbox folder.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/integromat-partner-post/integromat-dropbox-save-to-folder.png" alt="" height="398" width="1194"/>

    

            
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>This solution will automatically create, send, and store contracts in just a couple of minutes, beating the most eager, earnest attorneys and assistants by ridiculous margins. </p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="reflections-on-dropbox-automation">
    <h2 class="dr-article-content__section-title">Reflections on Dropbox automation</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The use case presented above is just an example of how Dropbox automation can improve tedious, time-consuming tasks.  </p>
<p>It goes without saying that contract automation is just the tip of the iceberg of what you can achieve with Dropbox and Integromat. </p>
<p>Other workflows that can be automated include:</p>
<ul>
<li><u><a href="https://www.integromat.com/en/integration/3667-create-zoho-invoices-from-shopify-orders-and-uploading-them-to-dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post">Creating and storing invoices from Shopify orders</a></u></li>
<li><u style="background-color: rgb(255,255,255);"><a href="https://www.integromat.com/en/integration/3311-add-attachments-received-by-gmail-to-a-dropbox-folder-and-notify-by-a-skype-message?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post" style="background-color: rgb(255,255,255);">Sending Gmail attachments to Dropbox folders </a></u></li>
<li><a href="https://www.integromat.com/en/integration/3263-upload-podcast-audio-to-dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post" style="background-color: rgb(255,255,255);"><u>Uploading podcast audio to Dropbox</u></a></li>
</ul>
<p>If your work involves sending and sharing files to and from Dropbox, chances are you can transform it with Integromat. </p>
<p>To conclude, none of this would be possible without the kind of APIs companies like Dropbox, HubSpot and Google offer. Integromat features multiple <a href="https://www.integromat.com/en/integrations/dropbox?utm_medium=partner&amp;utm_source=dropbox-tech&amp;utm_campaign=dropbox-guest-post"><u>Dropbox endpoints</u></a>, which anyone can use to automate tasks without the hassle of code, or costly development teams. </p>
<p>The potential of combining apps to automate workflows is huge, and not doing so is missing on immediate gains. </p>

</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><i>We hope you enjoyed this guest blog contribution from Jessica Herauf at Integromat, and that it gave you some ideas of how you can build powerful Dropbox integrations. </i><br />
</p>
<p><i>To learn more about Integromat and see more Dropbox modules and templates, head to </i><a href="https://www.integromat.com/"><i><u>integromat.com</u></i></a><i>. You can also contact Jessica Herauf directly at jessica.herauf@integromat.com. </i></p>
<p><i>If you have any questions about this or need help with anything else, you can always contact us </i><a href="https://www.dropbox.com/developers/contact"><i>here</i></a><i>.</i></p>
<p style="text-align: center;"><i>Build with Dropbox today at</i></p>
<p style="text-align: center;"><i>www.dropbox.com/developers</i></p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/developers/Developers-1-1440x305px-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/developers/Developers-1-1440x305px-light.png" medium="image">
        <media:title type="html">Automating contract management with Dropbox and Integromat</media:title>
      </media:content>
    </item>
    <item>
      <title>Atlas: Our journey from a Python monolith to a managed platform</title>
      <link>https://dropbox.tech/infrastructure/atlas--our-journey-from-a-python-monolith-to-a-managed-platform</link>
      <dc:creator>Naphat Sanguansin and Utsav Shah</dc:creator>
      <category>Python</category>
      <category>gRPC</category>
      <category>Service Oriented Architecture</category>
      <category>Envoy</category>
      <guid>https://dropbox.tech/infrastructure/atlas--our-journey-from-a-python-monolith-to-a-managed-platform</guid>
      <description><![CDATA[]]></description>
      <pubDate>Thu, 04 Mar 2021 10:00:00 -0800</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Dropbox, to our customers, needs to be a reliable and responsive service. As a company, we’ve had to scale constantly since our start, today serving more than 700M registered users in every time zone on the planet who generate at least 300,000 requests per second. Systems that worked great for a startup hadn’t scaled well, so we needed to devise a new model for our internal systems, and a way to get there without disrupting the use of our product.</p>
<p>In this post, we’ll explain why and how we developed and deployed Atlas, a platform which provides the majority of benefits of a <a href="https://en.wikipedia.org/wiki/Service-oriented_architecture">Service Oriented Architecture</a>, while minimizing the operational cost that typically comes with owning a service. </p>
<h3>Monolith should be by choice</h3>
<p>The majority of software developers at Dropbox contribute to server-side backend code, and all server side development takes place in our server <a href="https://dropbox.tech/application/speeding-up-a-git-monorepo-at-dropbox-with--200-lines-of-code">monorepo</a>. We mostly use Python for our server-side product development, with more than 3 million lines of code belonging to our monolithic Python server. </p>
<p>It works, but we realized the monolith was also holding us back as we grew. Developers wrangled daily with unintended consequences of the monolith. Every line of code they wrote was, whether they wanted or not, shared code—they didn’t get to choose what was smart to share, and what was best to keep isolated to a single endpoint. Likewise, in production, the fate of their endpoints was tied to every other endpoint, regardless of the stability, criticality, or level of ownership of these endpoints.</p>
<p>In 2020, we ran a project to break apart the monolith and evolve it into a serverless managed platform, which would reduce code tangles and liberate services and their underlying engineering teams from being entwined with one another. To do so, we had to innovate both the architecture (e.g. <a href="https://dropbox.tech/infrastructure/courier-dropbox-migration-to-grpc">standardizing on gRPC</a> and <a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">using </a><a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">Envoy’s g</a><a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">RPC</a><a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">-HTTP transcoding</a>) and the operations (e.g. introducing autoscaling and canary analysis). This blog post captures key ideas and learnings from our journey.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-metaserver-the-dropbox-monolith">
    <h2 class="dr-article-content__section-title"> Metaserver: The Dropbox monolith</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Dropbox’s internal service topology as of today can be thought of as a “solar system” model, in which a lot of product functionality is served by the monolith, but platform-level components like authentication, metadata storage, filesystem, and sync have been separated into different services.</p>
<p>About half of all commits to our server repository modify our large monolithic Python web application, Metaserver.</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/diagrams/Techblog-Atlas-720x912px-1.png" alt="diagram of existing serving stack" height="1824" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Extremely simplified view of existing serving stack</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Metaserver is one of our oldest services, created in 2007 by one of our co-founders. It has served Dropbox well, but as our engineering team marched to deliver new features over the years, the organic growth of the codebase led to serious challenges.</p>
<h3>Tangled codebase</h3>
<p>Metaserver’s code was originally organized in a simple pattern one might expect to see in a small open source project—library, model, controllers—with no centralized curation or guardrails to ensure the sustainability of the codebase. Over the years, the Metaserver codebase grew to become one of the most disorganized and tangled codebases in the company. </p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 python">//metaserver/controllers/ …
//metaserver/model/ …
//metaserver/lib/ …</code></pre>


</div>
<div class="dr-code-container-rte"><p>Metaserver Code Structure</p>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p><span style="">Because the codebase had multiple teams working on it, no single team felt strong ownership over codebase quality. For example, to unblock a product feature, a team would introduce import cycles into the codebase rather than refactor code. Even though this let us ship code faster in the short term, it left the codebase much less maintainable, and problems compounded.</span><br />
</p>
<h3>Inconsistent push cadence</h3>
<p>We push Metaserver to production for all our users daily. Unfortunately, with hundreds of developers effectively contributing to the same codebase, the likelihood of at least one critical bug being added every day had become fairly high. This would necessitate rollbacks and cherry picks of the entire monolith, and caused an inconsistent and unreliable push cadence for developers. Common best practices (for example, from <a href="https://www.amazon.com/dp/B07B9F83WM/ref=dp-kindle-redirect?_encoding=UTF8&amp;btkr=1">Accelerate</a>) point to fast, consistent deploys as the key to developer productivity. We were nowhere close to ideal on this dimension.</p>
<p>Inconsistent push cadence leads to unnecessary uncertainty in the development experience. For example, if a developer is working towards a product launch on day X, they aren’t sure whether their code should be submitted to our repository by day X-1, X-2 or even earlier, as another developer’s code might cause a critical bug in an unrelated component on day X and necessitate a rollback of the entire cluster completely unrelated to their own code.</p>
<h3>Infrastructure debt</h3>
<p>With a monolith of millions of lines of code, infrastructure improvements take much longer or never happen. For example, it had become impossible to stage a rollout of a new version of an HTTP framework or Python on only non-critical routes.</p>
<p>Additionally, Metaserver uses a legacy Python framework unused in most other Dropbox services or anywhere else externally. While our internal infrastructure stack evolved to use industry standard open source systems like <a href="https://dropbox.tech/infrastructure/courier-dropbox-migration-to-grpc">gRPC</a>, Metaserver was stuck on a deprecated legacy framework that unsurprisingly had poor performance and caused maintenance headaches due to esoteric bugs. For example, the legacy framework only supports HTTP/1.0 while modern libraries have moved to HTTP/1.1 as the minimum version. </p>
<p>Moreover, all the benefits we developed or integrated in our internal infrastructure, like <a href="https://dropbox.tech/infrastructure/monitoring-server-applications-with-vortex">i</a><a href="https://dropbox.tech/infrastructure/monitoring-server-applications-with-vortex">ntegrated metrics</a> and tracing, had to be hackily redone for Metaserver which was built atop different internal frameworks.</p>
<p>Over the past few years, we had spun up several workstreams to combat the issues we faced. Not all of them were all successful, but even those we gave up on paved the way to our current solution.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-soa-the-cost-of-operating-independent-services">
    <h2 class="dr-article-content__section-title"> SOA: the cost of operating independent services</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We tried to break up Metaserver as part of a larger push around a Service Oriented Architecture (SOA) initiative. The goal of SOA was to establish better abstractions and separation of concerns for functionalities at Dropbox—all problems that we wanted to solve in Metaserver. </p>
<p>The execution plan was simple: make it easy for teams to operate independent services in production, then carve out pieces of Metaserver into independent services. </p>
<p>Our SOA effort had two major milestones:</p>
<ol>
<li>Make it possible and easy to build services outside of Metaserver<ol type="a">
<li>Extract core functionalities like identity management from the monolith and expose them via RPC, to allow new functionalities to be built outside of Metaserver</li>
<li>Establish best practices and a production readiness process for smoothly and scalably onboarding new multiple services that serve customer-facing traffic, i.e. our live site services</li>
</ol>
</li>
<li>Break up Metaserver into smaller services owned and operated by various teams</li>
</ol>
<p>The SOA effort proved to be long and arduous. After over a year and a half, we were well into the first milestone. However, the experience from executing that first milestone exposed the flaws of the second milestone. As more teams and services were introduced into the critical path for customer traffic, we found it increasingly difficult to maintain a high reliability standard. This problem would only compound as we moved up the stack away from core functionalities and asked product teams to run services.</p>
<h3>No one solution for everything</h3>
<p>With this insight, we reassessed the problem. We found that product functionality at Dropbox could be divided into two broad categories:</p>
<ul>
<li>large, complex systems like all the logic around sharing a file</li>
<li>small, self-contained functionality, like the homepage</li>
</ul>
<p>For example, the “Sharing” service involves stateful logic around access control, rate limits, and quotas. On the other hand, the homepage is a fairly simple wrapper around our metadata store/filesystem service. It doesn’t change too often and it has very limited day to day operational burden and failure modes. In fact, operational issues for most routes served by Dropbox had common themes, like unexpected spikes of external traffic, or outages in underlying services. <br />
</p>
<p>This led us to an important conclusion:</p>
<ul>
<li><b>Small, self contained functionality doesn’t need independently operated services. </b>This is why we built Atlas.</li>
<li style="margin-left: 40.0px;">It’s unnecessary overhead for a product team to plan capacity, set up good alerts and multihoming (automatically running in multiple data centers) for small, simple functionality. Teams mostly want a place where they can write some logic, have it automatically run when a user hits a certain route, and get some automatic basic alerts if there are too many errors in their route. The code they submit to the repository should be deployed consistently, quickly and continuously.<br />
</li>
<li style="margin-left: 40.0px;">Most of our product functionality falls into this category. Therefore, Atlas should optimize for this category.<br />
</li>
<li>Large components should continue being their own services, with which Atlas happily coexists.</li>
<li style="margin-left: 40.0px;">Large systems can be operated by larger teams that sustainably manage the health of their systems. Teams should manage their own push schedules and set up dedicated alerts and verifiers.</li>
</ul>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-atlas-a-hybrid-approach">
    <h2 class="dr-article-content__section-title"> Atlas: a hybrid approach</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>With the fundamental sustainability problems we had with Metaserver, and the learning that migrating Metaserver into many smaller services was not the right solution for everything, we came up with Atlas, a managed platform for the self-contained functionality use case.</p>
<p>Atlas is a hybrid approach. It provides the user interface and experience of a “serverless” system like <a href="https://aws.amazon.com/fargate/">AWS Fargate</a> to Dropbox product developers, while being backed by automatically provisioned services behind the scenes. </p>
<p>As we said, the goal of Atlas is to provide the majority of benefits of SOA, while minimizing the operational costs associated with running a service. </p>
<p>Atlas is “managed,” which means that developers writing code in Atlas only need to write the interface and implementation of their endpoints. Atlas then takes care of creating a production cluster to serve these endpoints. The Atlas team owns pushing to and monitoring these clusters. </p>
<p>This is the experience developers might expect when contributing to a monolith versus Atlas:</p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/diagrams/Techblog-Atlas-720x485px-2.png" alt="diagram of before and after Atlas" height="970" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Before and after Atlas</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h2>Goals</h2>
<p>We designed Atlas with five ideal outcomes in mind:</p>
<ol>
<li><b>Code structure improvements</b><br />
Metaserver had no real abstractions on code sharing, which led to coupled code. Highly coupled code can be the hardest to understand and refactor, and the most likely to sprout bugs when modified. We wanted to introduce a structure and reduce coupling so that new code would be easier to read and modify.</li>
<li><b>Independent, consistent pushes</b><br />
The Metaserver push experience is great when it works. Product developers only have to worry about checking in code which will automatically get pushed to production. However, the aforementioned lack of push isolation led to an inconsistent experience. We wanted to create a platform where teams were not blocked on push due to a bug in unrelated code, and create the foundation for teams to push their own code in the future.</li>
<li><b>Minimized operational busywork</b><br />
We aimed to keep the operational benefits of Metaserver while providing some of the flexibility of a service. We set up automatic capacity management, automatic alerts, automatic canary analysis, and an automatic push process so that the migration from a monolith to a managed platform was smooth for product developers.</li>
<li><b>Infrastructure unification</b><br />
We wanted to unify all serving to standard open source components like gRPC. We don’t need to reinvent the wheel.</li>
<li><b>Isolation</b><br />
Some features like the homepage are more important than others. We wanted to serve these independently, so that an overload or bug in one feature could not spill over to the rest of Metaserver.</li>
</ol>
<p>We evaluated using off-the-shelf solutions to run the platform. But in order to de-risk our migration and ensure low engineering costs, it made sense for us to continue hosting services on the same deployment orchestration platform used by the rest of Dropbox. </p>
<p>However, we decided to remove custom components, such as our custom request proxy <a href="https://dropbox.tech/infrastructure/meet-bandaid-the-dropbox-service-proxy">Bandaid</a>, and replace them with open source systems like <a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">Envoy</a><a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy"> </a>that met our needs.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-technical-design">
    <h2 class="dr-article-content__section-title"> Technical design</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The project involved a few key efforts:</p>
<p><b>Componentization</b></p>
<ul>
<li>De-tangle the codebase by feature into components, to prevent future tangles</li>
<li>Enforce a single owner per component, so new functionality cannot be tacked onto a component by a non-owner</li>
<li>Incentivize fewer shared libraries and more code sharing via RPC</li>
</ul>
<p><b>Orchestration</b></p>
<ul>
<li>Automatically configure each component into a service in our deployment orchestration platform with &lt;50 lines of boilerplate code</li>
<li>Configure a proxy (Envoy) to send a request for a particular route to the right service, instead of simply sending each request to a Metaserver node</li>
<li>Configure services to speak to one another in gRPC instead of HTTP</li>
</ul>
<p><b>Operationalization</b></p>
<ul>
<li>Automatically configure a deployment pipeline that runs daily and pushes to production for each component </li>
<li>Set up automatic alerts and automatic analysis for regressions to each push pipeline to automatically pause and rollback in case of any problems</li>
<li>Automatically allocate additional hosts to scale up capacity via an autoscaler for each component based on traffic</li>
</ul>
<p>Let’s look at each of these in detail.</p>
<h3>Componentization</h3>
<p><b>Logical grouping of routes via servlets<br />
 </b>Atlas introduces Atlasservlets (pronounced “atlas servlets”) as a logical, atomic grouping of routes. For example, the home Atlasservlet contains all routes used to construct the homepage. The nav Atlasservlet contains all the routes used in the navigation bar on the Dropbox website.</p>
<p>In preparation for Atlas, we worked with product teams to assign Atlasservlets to every route in Metaserver, resulting in more than 200 Atlasservlets across more than 5000 routes. Atlasservlets are an essential tool for breaking up Metaserver.</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 python">//atlas/home/ …
//atlas/nav/ …
//atlas/&lt;some other atlasservlet&gt;/ …</code></pre>


</div>
<div class="dr-code-container-rte"><p>Atlas code structure, organized by servlets</p>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Each Atlasservlet is given a private directory in the codebase. The owner of the Atlasservlet has full ownership of this directory; they may organize it however they wish, and no one else can import from it. The Atlasservlet code structure inherently breaks up the Metaserver code monolith, requiring every endpoint to be in a private directory and make code sharing an explicit choice rather than an unexpected outcome of contributing to the monolith. </p>
<p>Having the Atlasservlet codified into our directory path also allows us to automatically generate production configs that would normally accompany a production service. Dropbox uses the <a href="https://bazel.build/">Bazel</a> build system for server side code, and we enforced prevention of imports through a Bazel feature called<a href="https://docs.bazel.build/versions/master/visibility.html"> visibility rules</a>, which allows library owners to control which code can use their libraries.</p>
<p><b>Breakup of import cycles<br />
</b><span style="">In order to break up our codebase, we had to break most of our Python import cycles. This took several years to achieve with a bunch of scripts and a lot of grunt work and refactoring. We prevented regressions and new import cycles through the same mechanism of Bazel visibility rules.</span><b><br />
</b></p>
<h2>Orchestration</h2>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/diagrams/Techblog-Atlas-720x526px-3.png" alt="diagram of Atlas cluster strategy" height="1052" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Atlas cluster strategy</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In Atlas, every Atlasservlet is its own cluster.  This gives us three important benefits:</p>
<ul>
<li><b>Isolation by default<br />
 </b>A misbehaving route will only impact other routes in the same Atlasservlet, which is owned by the same team anyway.</li>
<li><b>Independent pushes<br />
 </b>Each Atlasservlet can be pushed separately, putting product developers in control of their own destiny with respect to the consistency of their pushes.</li>
<li><b>Consistency<br />
 </b>Each Atlasservlet looks and behaves like any other internal service at Dropbox. So any tools provided by our infrastructure teams—e.g. periodic performance profiling—will work for all other teams’ Atlasservlets.</li>
</ul>
<p><b>gRPC Serving Stack<br />
 </b>One of our goals with Atlas was to unify our serving infrastructure. We chose to standardize on gRPC, a widely adopted tool at Dropbox. In order to continue to serve HTTP traffic, we used the gRPC-HTTP transcoding feature provided out of the box in Envoy, our proxy and load balancer. You can read more about Dropbox’s adoption of <a href="https://dropbox.tech/infrastructure/courier-dropbox-migration-to-grpc">gRPC</a> and <a href="https://dropbox.tech/infrastructure/how-we-migrated-dropbox-from-nginx-to-envoy">Envoy</a> in their respective blog posts.<b><br />
 </b></p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/diagrams/Techblog-Atlas-720x526px-4.png" alt="disgram of http transcoding" height="1052" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>http transcoding</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In order to facilitate our migration to gRPC, we wrote an adapter which takes an existing endpoint and converts it into the interface that gRPC expects, setting up any legacy in-memory state the endpoint expects. This allowed us to automate most of the migration code change. It also had the benefit of keeping the endpoint compatible with both Metaserver and Atlas during mid-migration, so we could safely move traffic between implementations.</p>
<h3>Operationalization</h3>
<p>Atlas’s secret sauce is the managed experience. Developers can focus on writing features without worrying about many operational aspects of running the service in production, while still retaining the majority of benefits that come with standalone services, like isolation. </p>
<p>The obvious drawback is that one team now bears the operational load of all 200+ clusters. Therefore, as part of the Atlas project we built several tools to help us effectively manage these clusters.</p>
<p><b>Automated Canary Analysis<br />
 </b>Metaserver (and Atlas by extension) is stateless. As a result one of the most common ways a failure gets introduced into the system is through code changes. If we can ensure that our push guardrails are as airtight as possible, this eliminates the majority of failure scenarios.<b><br />
 </b></p>

</div>
<div class="image c04-image aem-GridColumn aem-GridColumn--default--12">
<div class="dr-image image cq-dd-image  ">
    <figure class="dr-margin-0 dr-display-inline-block">
        
            
    

        

        
        
        

        
        
        

        
        
        

        
        <img src="/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/diagrams/Techblog-Atlas-720x502px-5.png" alt="diagram of canary analysis" height="1004" width="1440"/>
        

    

            <figcaption class="dr-typography-t5 dr-color-ink-60 dr-image-rte"><p>Canary analysis</p>
</figcaption>
        
    </figure>
</div></div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>We automate our failure checking through a simple canary analysis service very similar to Netflix’s <a href="https://netflixtechblog.com/automated-canary-analysis-at-netflix-with-kayenta-3260bc7acc69?gi=fd8ce01f9fb6">Kayenta</a>. Each Atlas service consists of three deployments: canary, control, and production, with canary and control receiving only a small random percentage of traffic. During the push, canary is restarted with the newest version of the code. Control is restarted with the old version of the code but at the same time as canary to ensure the operate from the same starting point. </p>
<p>We automatically compare metrics like CPU utilization and route availability from the canary and control deployments, looking for metrics where canary may have regressed relative to control. In a good push, canary will perform either equal to or better than control, and the push will be allowed to proceed. A bad push will be stopped automatically and the owners notified.</p>
<p>In addition to canary analysis, we also have alerts set up which are checked throughout the process, including in between the canary, control, and production pushes of a single cluster. This lets us automatically pause and rollback the push pipeline if something goes wrong.</p>
<p>Mistakes still happen. Bad changes may slip through. This is where Atlas’s default isolation comes in handy. Broken code will only impact its one cluster and can be rolled back individually, without blocking code pushes for the rest of the organization.</p>
<p><b>Autoscaling and capacity planning<br />
 </b>Atlas's clustering strategy results in a large number of small clusters. While this is great for isolation, it significantly reduces the headroom each cluster has to handle increases in traffic. Monoliths are large shared clusters, so a small RPS increase on a route is easily absorbed by the shared cluster. But when each Atlasservlet is its own service, a 10x increase in route traffic is harder to handle.</p>
<p>Capacity planning for 200+ clusters would cripple our team. Instead, we built an autoscaling system. The autoscaler monitors the utilization of each cluster in real time and automatically allocates machines to ensure that we stay above 40% free capacity headroom per cluster. This allows us to handle traffic increases as well as remove the need to do capacity planning. </p>
<p>The autoscaling system reads metrics from Envoy’s <a href="https://www.envoyproxy.io/docs/envoy/latest/api-v3/service/load_stats/v3/lrs.proto">Load Reporting Service</a> and uses <a href="https://developer.squareup.com/blog/autoscaling-based-on-request-queuing/">request queue length</a> to decide cluster size, and probably deserves its own blog post.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="execution">
    <h2 class="dr-article-content__section-title">Execution</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<h3>Stepping stones, not milestones</h3>
<p>Many previous efforts to improve Metaserver had not succeeded due to the size and complexity of the codebase. This time around, we wanted to deliver value to product developers even if we didn’t succeed in fully replacing Metaserver with Atlas. </p>
<p>The execution plan for Atlas was designed with <a href="https://medium.com/@jamesacowling/stepping-stones-not-milestones-e6be0073563f">stepping stones, not milestones</a> (as elegantly described by former Dropbox engineer James Cowling), so that each incremental step would provide sufficient value in case the next part of the project failed for any reason.</p>
<p>A few examples:</p>
<ul>
<li>We started off by speeding up testing frameworks in Metaserver, because we knew that an Atlas serving stack in tests might cause a regression in test times.</li>
<li>We had a constraint to significantly improve memory efficiency and reduce OOM kills when we migrated from Metaserver to Atlas, since we would be able to pack more processes per host and consume less capacity during the migration. We focused on delivering memory efficiency purely to Metaserver instead of tying the improvements to the Atlas rollout.</li>
<li>We designed a load test to prove that an Atlas MVP would be able to handle Metaserver traffic. We reused the load test to validate Metaserver’s performance on new hardware as part of a different project.</li>
<li>We backported workflow simplifications as much as feasible to Metaserver. For example, we backported some of the workflow improvements in Atlas to our web workflows in Metaserver.</li>
<li>Metaserver development workflows are divided into three categories based on the protocol: web, API, and internal gRPC. We focused Atlas on internal gRPC first to de-risk the new serving stack without needing the more risky parts like gRPC-HTTP transcoding. This in turn gave us an opportunity to improve workflows for internal gRPC independent of the remaining risky parts of Atlas.</li>
</ul>
<h3>Hurdles</h3>
<p>With a large migration like this, it’s no surprise that we ran into a lot of challenges. The issues faced could be their own blog post. We’ll summarize a few of the most interesting ones:</p>
<ul>
<li>The legacy HTTP serving stack contained quirky, surprising, and hard to replicate behavior that had to be ported over to prevent regressions. We powered through with a combination of reading the original source code, reusing legacy library functions where required, relying on various existing integration tests, and designing a key set of tests that compare byte-by-byte outputs of the legacy and new systems to safely migrate.</li>
<li>While splitting up Metaserver had wins in production, it was infeasible to spin up 200+ Python processes in our <a href="https://github.com/dropbox/dbx_build_tools">integration testing framework</a>. We decided to merge the processes back into a monolith for local development and testing purposes. We also built heavy integration with our Bazel rules, so that the merging happens behind the scene and developers can reference Atlasservlets as regular services.</li>
<li>Splitting up Metaserver in production broke many non-obvious assumptions that could not be caught easily in tests. For example, some infrastructure services had hardcoded the identity of Metaserver for access control. To minimize failures, we designed a meticulous and incremental migration plan with a clear understanding of the risks involved at each stage, and slowly monitored metrics as we rolled out the new system.</li>
<li>Engineering workflows in Metaserver had grown organically with the monolith, arriving at a state where engineers had to page in an enormous amount of context to get the simplest work done. In order to ensure that Atlas prioritizes and solves major engineering pain points, we brought on key product developers as partners in the design, then went through several rounds of iteration to set up a roadmap that would definitively solve both product and infrastructural needs.</li>
</ul>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="status">
    <h2 class="dr-article-content__section-title">Status</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Atlas is currently serving more than 25% of the previous Metaserver traffic. We have validated the remaining migration in tests. We’re on a clear path to deprecate Metaserver in the near future.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="conclusion">
    <h2 class="dr-article-content__section-title">Conclusion</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The single most important takeaway from this multi-year effort is that well-thought-out code composition, early in a project’s lifetime, is essential. Otherwise, technical debt and code complexity compounds very quickly. The dismantling of import cycles and decomposition of Metaserver into feature based directories was probably the most strategically effective part of the project, because it prevented new code from contributing to the problem and also made our code simpler to understand.</p>
<p>By shipping a managed platform, we took a thoughtful approach on how to break up our Metaserver monolith. We learned that monoliths have many benefits (<a href="https://shopify.engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity">as</a><a href="https://shopify.engineering/deconstructing-monolith-designing-software-maximizes-developer-productivity"> discussed by Shopify</a>) and blindly splitting up our monolith into services would have increased operational load to our engineering organization.</p>
<p>In our view, developers don’t care about the distinction between monoliths and services, and simply want the lowest-overhead way to deliver end value to customers. So we have very little doubt that a managed platform which removes operational busywork like capacity planning, while providing maximum flexibility like fast releases, is the way forward. We’re excited to see the industry move toward such platforms.</p>
<h3>We’re hiring!</h3>
<p>If you’re interested in solving large problems with innovative, unique solutions—at a company where your push schedule is more predictable : ) —please check out our <a href="https://www.dropbox.com/jobs/teams/engineering#open-positions">open positions</a>.</p>
<h3>Acknowledgements</h3>
<p>Atlas was a result of the work of a large number of Dropboxers and Dropbox alumni, including but certainly not limited to: Agata Cieplik, Aleksey Kurkin, Andrew Deck, Andrew Lawson, David Zbarsky, Dmitry Kopytkov, Jared Hance, Jeremy Johnson, Jialin Xu, Jukka Lehtosalo, Karandeep Johar, Konstantin Belyalov, Ivan Levkivskyi, Lennart Jansson, Phillip Huang, Pranay Sowdaboina, Pranesh Pandurangan, Ruslan Nigmatullin, Taylor McIntyre, and Yi-Shu Tai.</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/headers/Infrastructure-Atlas-1440x305-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/2021/03/atlas/headers/Infrastructure-Atlas-1440x305-light.png" medium="image">
        <media:title type="html">Atlas: Our journey from a Python monolith to a managed platform</media:title>
      </media:content>
    </item>
    <item>
      <title>New Paper Endpoints Released in Preview</title>
      <link>https://dropbox.tech/developers/new-paper-endpoints-released-in-preview</link>
      <dc:creator>Jess Kenney</dc:creator>
      <category>Announcements</category>
      <category>Preview</category>
      <category>Paper</category>
      <guid>https://dropbox.tech/developers/new-paper-endpoints-released-in-preview</guid>
      <description><![CDATA[New endpoints are available to interact with Paper in the File System using the Dropbox API.]]></description>
      <pubDate>Wed, 03 Mar 2021 12:15:00 -0800</pubDate>
      <content:encoded><![CDATA[


<div class="aem-Grid aem-Grid--12 aem-Grid--default--12 ">
    
    <div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>In September 2019, we began to represent <a href="https://www.dropbox.com/paper">Dropbox Paper</a> files as <a href="https://aem.dropbox.com/en-us/lp/developers/reference/paper-migration-guide">.paper documents in the filesystem</a>. This enabled listing, moving, and exporting paper docs with /files endpoints.</p>
<p>Today, we’ve added new endpoints for Paper—now you can create, update, and even append to paper documents in the filesystem! Paper docs can be added using Markdown, HTML, or plain text.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-new-and-updated-apis">
    <h2 class="dr-article-content__section-title"> New and Updated APIs</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The following APIs have been added or modified:</p>
<ul>
<li><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-paper-create">/files/paper/create</a> - Use this new endpoint to create new Paper docs</li>
<li><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-paper-update">/files/paper/update</a> - Use this new endpoint to overwrite or append Paper docs</li>
<li><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-export">/files/export</a> - Use this endpoint to get metadata and a Markdown, HTML, or plain text representation of a Paper doc. This endpoint has been updated to support new Paper export formats and metadata.</li>
</ul>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-creating-a-paper-doc">
    <h2 class="dr-article-content__section-title"> Creating a Paper Doc</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Creating a paper doc is easy—conventions are similar to <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-upload">uploading binary files</a>. Simply specify your target path and input format with the <span class="dr-code">Dropbox-API-Arg</span> header with your text, Markdown, or HTML as the body.</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 bash">curl -v -X POST https://api.dropboxapi.com/2/files/paper/create     
--header &quot;Authorization: Bearer YOUR_BEARER_TOKEN&quot;     
--header &quot;Dropbox-API-Arg: {\&quot;path\&quot;: \&quot;/Meeting Notes.paper\&quot;,\&quot;import_format\&quot;: \&quot;plain_text\&quot;}&quot;     
--header &quot;Content-Type: application/octet-stream&quot;      
--data-binary @meeting_notes.txt</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>The <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-paper-create">/files/paper</a><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-paper-create">/create</a> call will return the URL, which is presentable to end users to visit and begin editing (Note: permissions on the link can be managed through sharing APIs). The call will also return the <span class="dr-code">result_path</span> and <span class="dr-code">file_id</span>, which can be used with other file operators (like <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-move">/files/</a><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-move">move</a> and <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-delete">/files/</a><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-delete">delete</a>).  </p>
<p>Note that if a file already exists at your target destination, create will append a number to the end of the path to prevent a collision.</p>

</div>
<div class="dr-code-container aem-GridColumn aem-GridColumn--default--12">




<div class="dr-code-container--title" />
<div class="dr-code-container-inner">

    <button class="dr-code-container__copy-button dr-button dr-typography-t17">
        Copy
    </button>
    <pre class="dr-code-container__pre"><code class="dr-code-container__code dr-typography-t5 json">{
    &quot;url&quot;: &quot;https://www.dropbox.com/cloud_docs/view/k93hadJEO3-sRkejKYJi4?fileid_gid=0uVLNNU2EdAAAAAAAABTcw&quot;,
    &quot;result_path&quot;: &quot;/Meeting Notes (1).paper&quot;,
    &quot;file_id&quot;: &quot;id:0uVLZNU2SdAAAAAAAAATcw&quot;,
    &quot;paper_revision&quot;: 2
}</code></pre>


</div>
<div class="dr-code-container-rte" />
</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-updating-a-paper-doc">
    <h2 class="dr-article-content__section-title"> Updating a Paper Doc</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>Updating a paper document with <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-paper-update">/files/paper/update</a> is similar. Pass the path, input format, and binary content.</p>
<p>Update also enables you to specify the <span class="dr-code">doc_update_policy</span>. The <span class="dr-code">append</span> and <span class="dr-code">prepend</span> modes allow you to add content to an existing doc. The <span class="dr-code">overwrite</span> mode will overwrite the entire document, and the <span class="dr-code">update</span> mode overwrites after checking that there are no updates the caller has missed.</p>
<p>Dropbox Paper enables live, real-time co-editing. The <span class="dr-code">paper_revision</span> increments for every change to the document. The <span class="dr-code">paper_revision</span> can be passed when using the <span class="dr-code">update</span> mode, which will then error if <span class="dr-code">paper_revision</span> has changed by the time the call reaches Dropbox servers. This provides a mechanism to make sure your programmatic updates do not conflict with any edits made by users.  Other update modes to not require the <span class="dr-code">paper_revision</span>.</p>
<p>Note that <span class="dr-code">paper_revision</span> and <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-list_revisions">file revision</a> are different, but related: <span class="dr-code">paper_revision</span> tracks rapid, live updates — which Paper will then batch together to make a <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-list_revisions">file revision</a>.  Use <a href="https://www.dropbox.com/developers/documentation/http/documentation#files-export"> </a><a href="https://www.dropbox.com/developers/documentation/http/documentation#files-export">/files/export</a> to retrieve the latest <span class="dr-code">paper_revision</span>.</p>

</div>
<div class="section aem-GridColumn aem-GridColumn--default--12">
<div class="dr-article-content__section" id="-building-with-paper">
    <h2 class="dr-article-content__section-title"> Building with Paper</h2>
</div>
</div>
<div class="text parbase aem-GridColumn aem-GridColumn--default--12">
<p>These new APIs are in preview, available to all developers.   </p>
<p>Note that at the time of writing, not all users have access to paper docs in the filesystem—you may need to issue an API call to <a href="https://www.dropbox.com/developers/documentation/http/documentation#users-features-get_values"><u>/users/features/get_values</u></a> to check for availability on a per-user basis. See our <a href="https://aem.dropbox.com/en-us/lp/developers/reference/paper-migration-guide">Paper Migration Guide</a> for more information.</p>
<p>As always, we’re available to help! You can post your questions on our <a href="https://www.dropboxforum.com/t5/Discuss-Developer-API/ct-p/101000041B">developer forum</a> or <a href="https://www.dropbox.com/developers/contact">submit a ticket</a> for more direct support.  </p>
<p>Build with Dropbox today at <u>www.dropbox.com/developers</u>.<br />
</p>

</div>

    
</div>
]]></content:encoded>
      <media:thumbnail url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/developers/Developers-3-1440x305px-light.png"/>
      <media:content url="https://dropbox.tech/cms/content/dam/dropbox/tech-blog/en-us/developers/Developers-3-1440x305px-light.png" medium="image">
        <media:title type="html">New Paper Endpoints Released in Preview</media:title>
      </media:content>
    </item>
  </channel>
</rss>
